<!DOCTYPE html>
<html lang="ja"><head><title>【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場 | ほこりログ</title><meta charset="utf-8"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=M PLUS Rounded 1c:wght@400;500;700&amp;family=M PLUS Rounded 1c:ital,wght@0,400;0,500;0,700;1,400;1,500;1,700&amp;family=JetBrains Mono:wght@400;500;700&amp;display=swap"/><link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin="anonymous"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="og:site_name" content="ほこりログ"/><meta property="og:title" content="【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場 | ほこりログ"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場 | ほこりログ"/><meta name="twitter:description" content="AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで  AI Engineer World's Fairが開催され、多くの発表がありましたが、それ以外にもAI分野では目まぐるしい技術革新が続いています。MistralがCodeプロジェクトを立ち上げたり、Cursorが1.0に到達したり、AnthropicがClaude Codeのプランを改善したり、Chat..."/><meta property="og:description" content="AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで  AI Engineer World's Fairが開催され、多くの発表がありましたが、それ以外にもAI分野では目まぐるしい技術革新が続いています。MistralがCodeプロジェクトを立ち上げたり、Cursorが1.0に到達したり、AnthropicがClaude Codeのプランを改善したり、Chat..."/><meta property="og:image:alt" content="AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで  AI Engineer World's Fairが開催され、多くの発表がありましたが、それ以外にもAI分野では目まぐるしい技術革新が続いています。MistralがCodeプロジェクトを立ち上げたり、Cursorが1.0に到達したり、AnthropicがClaude Codeのプランを改善したり、Chat..."/><meta property="twitter:domain" content="blog.tachibanayu24.com"/><meta property="og:url" content="https://blog.tachibanayu24.com/news/ai-latest-updates-jun25"/><meta property="twitter:url" content="https://blog.tachibanayu24.com/news/ai-latest-updates-jun25"/><link rel="icon" href="../static/icon.png"/><meta name="description" content="AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで  AI Engineer World's Fairが開催され、多くの発表がありましたが、それ以外にもAI分野では目まぐるしい技術革新が続いています。MistralがCodeプロジェクトを立ち上げたり、Cursorが1.0に到達したり、AnthropicがClaude Codeのプランを改善したり、Chat..."/><meta name="generator" content="Quartz"/><link href="../index.css" rel="stylesheet" type="text/css" spa-preserve/><style>.expand-button {
  position: absolute;
  display: flex;
  float: right;
  padding: 0.4rem;
  margin: 0.3rem;
  right: 0;
  color: var(--gray);
  border-color: var(--dark);
  background-color: var(--light);
  border: 1px solid;
  border-radius: 5px;
  opacity: 0;
  transition: 0.2s;
}
.expand-button > svg {
  fill: var(--light);
  filter: contrast(0.3);
}
.expand-button:hover {
  cursor: pointer;
  border-color: var(--secondary);
}
.expand-button:focus {
  outline: 0;
}

pre:hover > .expand-button {
  opacity: 1;
  transition: 0.2s;
}

#mermaid-container {
  position: fixed;
  contain: layout;
  z-index: 999;
  left: 0;
  top: 0;
  width: 100vw;
  height: 100vh;
  overflow: hidden;
  display: none;
  backdrop-filter: blur(4px);
  background: rgba(0, 0, 0, 0.5);
}
#mermaid-container.active {
  display: inline-block;
}
#mermaid-container > #mermaid-space {
  border: 1px solid var(--lightgray);
  background-color: var(--light);
  border-radius: 5px;
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  height: 80vh;
  width: 80vw;
  overflow: hidden;
}
#mermaid-container > #mermaid-space > .mermaid-content {
  padding: 2rem;
  position: relative;
  transform-origin: 0 0;
  transition: transform 0.1s ease;
  overflow: visible;
  min-height: 200px;
  min-width: 200px;
}
#mermaid-container > #mermaid-space > .mermaid-content pre {
  margin: 0;
  border: none;
}
#mermaid-container > #mermaid-space > .mermaid-content svg {
  max-width: none;
  height: auto;
}
#mermaid-container > #mermaid-space > .mermaid-controls {
  position: absolute;
  bottom: 20px;
  right: 20px;
  display: flex;
  gap: 8px;
  padding: 8px;
  background: var(--light);
  border: 1px solid var(--lightgray);
  border-radius: 6px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  z-index: 2;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 32px;
  height: 32px;
  padding: 0;
  border: 1px solid var(--lightgray);
  background: var(--light);
  color: var(--dark);
  border-radius: 4px;
  cursor: pointer;
  font-size: 16px;
  font-family: var(--bodyFont);
  transition: all 0.2s ease;
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:hover {
  background: var(--lightgray);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:active {
  transform: translateY(1px);
}
#mermaid-container > #mermaid-space > .mermaid-controls .mermaid-control-button:nth-child(2) {
  width: auto;
  padding: 0 12px;
  font-size: 14px;
}
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,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 */</style><link href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><script src="../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch("../static/contentIndex.json").then(data => data.json())</script><link rel="alternate" type="application/rss+xml" title="RSS Feed" href="https://blog.tachibanayu24.com/index.xml"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image" content="https://blog.tachibanayu24.com/news/ai-latest-updates-jun25-og-image.webp"/><meta property="og:image:url" content="https://blog.tachibanayu24.com/news/ai-latest-updates-jun25-og-image.webp"/><meta name="twitter:image" content="https://blog.tachibanayu24.com/news/ai-latest-updates-jun25-og-image.webp"/><meta property="og:image:type" content="image/.webp"/></head><body data-slug="news/ai-latest-updates-jun25"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h2 class="page-title"><a href=".."><img style="margin:0;" src="../static/hokori_log.png" alt="icon"/></a></h2><div class="spacer mobile-only"></div><div style="display: flex; flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search desktop-only"><button class="search-button" style="margin-top:1rem;margin-bottom:-2rem;"><p style="font-size:0.8rem;">検索（⌘+K）</p><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="検索ワードを入力" placeholder="検索ワードを入力"/><div class="search-layout" data-preview="true"></div></div></div></div></div></div><div style="display: flex; flex-direction: row; flex-wrap: nowrap; gap: 1rem;"><div style="flex-grow: 1; flex-shrink: 1; flex-basis: auto; order: 0; align-self: center; justify-self: center;"><div class="search mobile-only"><button class="search-button"><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title>Search</title><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></button><div class="search-container"><div class="search-space"><input autocomplete="off" class="search-bar" name="search" type="text" aria-label="検索ワードを入力" placeholder="検索ワードを入力"/><div class="search-layout" data-preview="true"></div></div></div></div></div></div><div class="desktop-only"><div class="profile"><img src="https://pbs.twimg.com/profile_images/1582323777756876801/rtFFKM1E_400x400.jpg" alt="Profile"/><div class="profile-info"><p class="profile-name">たちばなゆうと</p><p class="profile-description">ソフトウェアエンジニアです。<br/>スタートアップや金融, 不動産, うさぎが好きです。</p><div class="profile-links"><a href="https://x.com/tachibanayu24" target="_blank" rel="noopener noreferrer"><svg fill="none" height="16" width="16" xmlns="http://www.w3.org/2000/svg" viewBox="0.254 0.25 500 451.95400000000006"><path d="M394.033.25h76.67L303.202 191.693l197.052 260.511h-154.29L225.118 294.205 86.844 452.204H10.127l179.16-204.77L.254.25H158.46l109.234 144.417zm-26.908 406.063h42.483L135.377 43.73h-45.59z" fill="#5d4a3c"></path></svg></a><a href="https://github.com/tachibanayu24" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" viewBox="0 0 256 249" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMinYMin meet"><g fill="#5d4a3c"><path d="M127.505 0C57.095 0 0 57.085 0 127.505c0 56.336 36.534 104.13 87.196 120.99 6.372 1.18 8.712-2.766 8.712-6.134 0-3.04-.119-13.085-.173-23.739-35.473 7.713-42.958-15.044-42.958-15.044-5.8-14.738-14.157-18.656-14.157-18.656-11.568-7.914.872-7.752.872-7.752 12.804.9 19.546 13.14 19.546 13.14 11.372 19.493 29.828 13.857 37.104 10.6 1.144-8.242 4.449-13.866 8.095-17.05-28.32-3.225-58.092-14.158-58.092-63.014 0-13.92 4.981-25.295 13.138-34.224-1.324-3.212-5.688-16.18 1.235-33.743 0 0 10.707-3.427 35.073 13.07 10.17-2.826 21.078-4.242 31.914-4.29 10.836.048 21.752 1.464 31.942 4.29 24.337-16.497 35.029-13.07 35.029-13.07 6.94 17.563 2.574 30.531 1.25 33.743 8.175 8.929 13.122 20.303 13.122 34.224 0 48.972-29.828 59.756-58.22 62.912 4.573 3.957 8.648 11.717 8.648 23.612 0 17.06-.148 30.791-.148 34.991 0 3.393 2.295 7.369 8.759 6.117 50.634-16.879 87.122-64.656 87.122-120.973C255.009 57.085 197.922 0 127.505 0"></path><path d="M47.755 181.634c-.28.633-1.278.823-2.185.389-.925-.416-1.445-1.28-1.145-1.916.275-.652 1.273-.834 2.196-.396.927.415 1.455 1.287 1.134 1.923M54.027 187.23c-.608.564-1.797.302-2.604-.589-.834-.889-.99-2.077-.373-2.65.627-.563 1.78-.3 2.616.59.834.899.996 2.08.36 2.65M58.33 194.39c-.782.543-2.06.034-2.849-1.1-.781-1.133-.781-2.493.017-3.038.792-.545 2.05-.055 2.85 1.07.78 1.153.78 2.513-.019 3.069M65.606 202.683c-.699.77-2.187.564-3.277-.488-1.114-1.028-1.425-2.487-.724-3.258.707-.772 2.204-.555 3.302.488 1.107 1.026 1.445 2.496.7 3.258M75.01 205.483c-.307.998-1.741 1.452-3.185 1.028-1.442-.437-2.386-1.607-2.095-2.616.3-1.005 1.74-1.478 3.195-1.024 1.44.435 2.386 1.596 2.086 2.612M85.714 206.67c.036 1.052-1.189 1.924-2.705 1.943-1.525.033-2.758-.818-2.774-1.852 0-1.062 1.197-1.926 2.721-1.951 1.516-.03 2.758.815 2.758 1.86M96.228 206.267c.182 1.026-.872 2.08-2.377 2.36-1.48.27-2.85-.363-3.039-1.38-.184-1.052.89-2.105 2.367-2.378 1.508-.262 2.857.355 3.049 1.398"></path></g></svg></a></div></div></div></div><div class="recent-notes desktop-only"><h3>最近の更新</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/chinese-models-jun25" class="internal">【bot投稿🤖】中国発新モデル AI開発競争と最新動向</a></h3></div><p class="meta"><time datetime="2025-06-17T03:55:26.000Z">2025年6月17日</time></p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/ai-latest-updates-jun25" class="internal">【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場</a></h3></div><p class="meta"><time datetime="2025-06-05T05:52:28.000Z">2025年6月05日</time></p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/meeker-ai-deepseek-r1" class="internal">【bot投稿🤖】メアリーミーカー氏のAIレポートなど</a></h3></div><p class="meta"><time datetime="2025-05-31T03:49:43.000Z">2025年5月31日</time></p></div></li></ul><p style="text-align:right;padding-right:1rem;"><a href="../tags/" style="font-size:0.8rem;">さらに19件 →</a></p></div><div class="explorer" data-behavior="collapse" data-collapsed="collapsed" data-savestate="true" data-data-fns="{&quot;order&quot;:[&quot;filter&quot;,&quot;map&quot;,&quot;sort&quot;],&quot;sortFn&quot;:&quot;(a,b)=>!a.isFolder&amp;&amp;!b.isFolder||a.isFolder&amp;&amp;b.isFolder?a.displayName.localeCompare(b.displayName,void 0,{numeric:!0,sensitivity:\&quot;base\&quot;}):!a.isFolder&amp;&amp;b.isFolder?1:-1&quot;,&quot;filterFn&quot;:&quot;node=>node.slugSegment!==\&quot;tags\&quot;&quot;,&quot;mapFn&quot;:&quot;node=>node&quot;}"><button type="button" class="explorer-toggle mobile-explorer hide-until-loaded" data-mobile="true" aria-controls="explorer-content"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide-menu"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg></button><button type="button" class="title-button explorer-toggle desktop-explorer" data-mobile="false" aria-expanded="true"><h2 style="font-size:0.8rem;color:var(--darkgray);">記事一覧</h2><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div class="explorer-content" aria-expanded="false"><ul class="explorer-ul overflow" id="list-0"><li class="overflow-end"></li></ul></div><template id="template-file"><li><a href="#"></a></li></template><template id="template-folder"><li><div class="folder-container"><div><button class="folder-button"><span class="folder-title"></span></button></div></div><div class="folder-outer"><ul class="content"></ul></div></li></template></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container" aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../">Top</a><p> / </p></div><div class="breadcrumb-element"><a href="../news/">news</a><p> / </p></div><div class="breadcrumb-element"><a href>【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場</a></div></nav><h1 class="article-title">【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場</h1><p style="font-size:0.8rem;" show-comma="true" class="content-meta"><time datetime="2025-06-05T05:52:28.000Z">2025年6月05日</time><span>19分くらいで読めます</span></p><ul class="tags"><li><a href="../tags/自動生成記事" class="internal tag-link">自動生成記事</a></li><li><a href="../tags/LMM" class="internal tag-link">LMM</a></li></ul></div></div><article class="popover-hint"><blockquote class="callout warning" data-callout="warning">
<div class="callout-title">
                  <div class="callout-icon"></div>
                  <div class="callout-title-inner"><p>Warning</p></div>
                  
                </div>
<div class="callout-content">
<p>この記事は、以下の情報源を参照し、LLMにより自動で生成・投稿された記事です。</p>
<ul>
<li><a href="https://news.smol.ai/" class="external" target="_blank">AINews<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></li>
</ul>
<p>内容の正確性にご注意ください。</p>
</div>
</blockquote>
<h1 id="ai技術の最新動向一挙まとめ-google-deepsearchからnvidia新モデルまで">AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#ai技術の最新動向一挙まとめ-google-deepsearchからnvidia新モデルまで" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h1>
<p>AI Engineer World’s Fairが開催され、多くの発表がありましたが、それ以外にもAI分野では目まぐるしい技術革新が続いています。Mistralが<a href="https://mistral.ai/products/mistral-code" class="external" target="_blank">Codeプロジェクト<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>を立ち上げたり、<a href="https://www.cursor.com/en/changelog/1-0" class="external" target="_blank">Cursorが1.0に到達<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>したり、Anthropicが<a href="https://youtu.be/Yf_1w00qIKc?si=wDtapcnvLfnq5ip4" class="external" target="_blank">Claude Codeのプランを改善<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>したり、ChatGPTが<a href="https://x.com/openai/status/1930319398897889707?s=46" class="external" target="_blank">さらなる接続強化を発表<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>したりと、話題に事欠きません。今回は、これらの最新情報をまとめてご紹介します。</p>
<h2 id="google-deepsearchスタックのオープンソース化">Google DeepSearchスタックのオープンソース化<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#google-deepsearchスタックのオープンソース化" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Googleは、新しいDeepSearchスタックをオープンソースとして公開しました。これは<a href="https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart" class="external" target="_blank">gemini-fullstack-langgraph-quickstartリポジトリ<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>からアクセス可能で、Gemini 2.5とLangGraphオーケストレーションフレームワークを使用してフルスタックのAIエージェントを構築するためのテンプレートとして提供されています。</p>
<ul>
<li><strong>主な特徴</strong>
<ul>
<li>Gemini 2.5とLangGraphを活用</li>
<li>Gemmaのような他のローカルLLMとの連携も視野に</li>
<li>Dockerとモジュラープロジェクト構造による迅速なプロトタイピング</li>
<li>GoogleのGeminiアプリで使用されている実際のバックエンドとは異なるものの、エージェントベースのアーキテクチャを試す良い出発点</li>
</ul>
</li>
<li><strong>コミュニティの反応</strong>
<ul>
<li>よく構造化されたデモであり、LangGraphのオーケストレーターとしての可能性に注目が集まっている</li>
<li>より複雑なLangGraphベースのシステムとしては<a href="https://github.com/Darwin-lfl/langmanus/tree/main" class="external" target="_blank">LangManus<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>なども存在する</li>
</ul>
</li>
</ul>
<h2 id="metaの論文言語モデルはどれだけ記憶するのか">Metaの論文：言語モデルはどれだけ記憶するのか<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#metaの論文言語モデルはどれだけ記憶するのか" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Metaからは、言語モデルの記憶容量を厳密に推定する手法を提案する論文（<a href="https://arxiv.org/abs/2505.24832" class="external" target="_blank">arXiv:2505.24832<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>）が発表されました。</p>
<ul>
<li><strong>主な発見</strong>
<ul>
<li>GPTスタイルのトランスフォーマーは、パラメータあたり約3.5〜4ビットの情報を一貫して保存する
<ul>
<li>例: bfloat16で3.51ビット/パラメータ、float32で3.83ビット/パラメータ</li>
</ul>
</li>
<li>記憶容量は、精度の向上と線形にスケールしない</li>
<li>モデル容量が飽和すると記憶から汎化（「grokking」）へ移行し、データセットの情報量がモデルの記憶限界を超えると二重降下（double descent）が始まる</li>
</ul>
</li>
<li><strong>議論のポイント</strong>
<ul>
<li>これらの発見がMixture-of-Expert（MoE）モデルにどう適用されるか</li>
<li>量子化（特に3.5ビット/パラメータ未満）や低精度/QAT（Quantization-Aware Training）が記憶と汎化の境界にどう影響するか</li>
<li>BitNetのような新しいアーキテクチャがこれらの基本的な容量限界を変える可能性があるか</li>
</ul>
</li>
</ul>
<h2 id="nvidia-nemotron-research-reasoning-qwen-15b">Nvidia Nemotron-Research-Reasoning-Qwen-1.5B<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#nvidia-nemotron-research-reasoning-qwen-15b" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Nvidiaは、複雑な推論タスク（数学、コーディング、STEM、論理）に特化した1.5Bパラメータのオープンウェイトモデル<a href="https://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B" class="external" target="_blank">Nemotron-Research-Reasoning-Qwen-1.5B<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>を発表しました。</p>
<ul>
<li><strong>主な特徴</strong>
<ul>
<li>Prolonged Reinforcement Learning (ProRL)という新しいアプローチで訓練</li>
<li>DeepSeek-R1-1.5Bを大幅に上回り、一部タスクではDeepSeek-R1-7Bに匹敵またはそれを超える性能を達成
<ul>
<li>pass@1の平均改善率: 数学14.7%、コーディング13.9%、論理54.8%、STEM 25.1%、指示追従18.1%</li>
</ul>
</li>
<li>GGUF形式で量子化オプション（q4, q8, f16）も提供</li>
</ul>
</li>
<li><strong>懸念点</strong>
<ul>
<li>ライセンスがCC-BY-NC-4.0であり、商用利用が制限される</li>
</ul>
</li>
</ul>
<h2 id="vision-language-model-vlm-のバイアス">Vision Language Model (VLM) のバイアス<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#vision-language-model-vlm-のバイアス" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>最新のVLMは、標準的な視覚タスク（例：典型的な動物の足の数を数える）ではほぼ完璧な精度を達成しますが、反事実的または変更されたシナリオでは精度が約17%にまで大幅に低下することが<a href="https://vlmsarebiased.github.io/" class="external" target="_blank">VLMBiasベンチマーク<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>で示されました。</p>
<ul>
<li><strong>主な分析結果</strong>
<ul>
<li>モデルは実際の視覚入力よりも記憶された事前知識に大きく依存している</li>
<li>エラーの75.7%は曖昧さではなくステレオタイプな知識を反映</li>
<li>明示的なバイアス緩和プロンプトはほとんど効果がない</li>
<li>この現象は、LLMの対数確率で見られる問題と類似しているとの指摘もある</li>
</ul>
</li>
</ul>
<h2 id="aiによる動画生成とコンテンツ制作の革新">AIによる動画生成とコンテンツ制作の革新<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#aiによる動画生成とコンテンツ制作の革新" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="google-veo-3による低コストcm制作">Google Veo 3による低コストCM制作<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#google-veo-3による低コストcm制作" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>ブラジルのウリアノポリス市役所が、GoogleのVeo 3を使用して、わずかR<span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">300</span><span class="mord cjk_fallback">（約</span><span class="mord">52</span><span class="mord cjk_fallback">米ドル）の</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord cjk_fallback">クレジット費用でプロ品質の</span><span class="mord">1</span><span class="mord cjk_fallback">分間のコマーシャルを制作しました。これは従来の制作コスト（</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span>100,000超 / 約17,500米ドル）と比較して劇的な削減です。</p>
<ul>
<li>テキストから動画を生成する機能により、監督、脚本、撮影、編集、ポストプロダクションなど、従来の制作プロセスのほぼ全てを置き換えた</li>
<li>特に、AI生成モデルにとって課題であったネイティブ言語（ブラジルポルトガル語）の自然な発音や表現の品質が高く評価されている</li>
</ul>
<h3 id="microsoft-bingでのsora-ai動画生成">Microsoft BingでのSora AI動画生成<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#microsoft-bingでのsora-ai動画生成" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Microsoftは、OpenAIのSora AI動画生成モデルをBingアプリに「Bing Video Creator」として統合し、無料で提供を開始しました。</p>
<ul>
<li>現時点では専用のSoraアプリやChatGPTへの統合はない</li>
<li>詳細なアニメーションコンテンツを生成できる一方で、コンテンツモデレーションが厳しく、多くのリクエストがブロックされるとの報告がある</li>
<li>GoogleのVeo3と比較すると、動画の品質で劣るという意見もある</li>
</ul>
<h2 id="openaiの新たな動き">OpenAIの新たな動き<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#openaiの新たな動き" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="ネイティブオーディオサポート付き新モデル">ネイティブオーディオサポート付き新モデル<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#ネイティブオーディオサポート付き新モデル" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>OpenAIは、「gpt-4o-audio-preview-2025-06-03」と「gpt-4o-realtime-preview-2025-06-03」という2つの新しいモデルをリリースする準備をしていると報じられています。これらのモデルは、外部の音声認識（STT）や音声合成（TTS）モジュールに依存せず、ネイティブなオーディオ処理機能を備えているとされています。これにより、低遅延の音声対話やよりシームレスなアシスタント機能が期待されます。</p>
<h3 id="chatgptのmemory機能が無料ユーザーにも">ChatGPTのMemory機能が無料ユーザーにも<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#chatgptのmemory機能が無料ユーザーにも" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>ChatGPTのMemory機能が無料ユーザーにも提供開始されました（2025年6月3日より順次展開）。これにより、ChatGPTが最近の会話内容を記憶し、より関連性の高い応答を提供できるようになります。欧州の一部地域では手動での有効化が必要ですが、それ以外の地域ではデフォルトで有効になります。ユーザーはいつでもこの機能を無効にできます。</p>
<ul>
<li>技術的な議論としては、プライバシー（有料ユーザーはデータがモデル訓練に使われないオプトアウトが可能）や、自動保存による不要な情報の記憶、より詳細な手動制御の要望などが挙がっている</li>
</ul>
<h3 id="codexがplusユーザーへ展開">CodexがPlusユーザーへ展開<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#codexがplusユーザーへ展開" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>OpenAIのコード生成に特化したモデルファミリーであるCodexが、ChatGPT Plusユーザー向けに段階的に有効化されています。<a href="https://chatgpt.com/codex" class="external" target="_blank">https://chatgpt.com/codex<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> からアクセスできるとの報告があります。利用制限やPlusユーザー向けの具体的な機能については、まだ詳細が明らかにされていません。</p>
<h2 id="anthropic-claude-proにresearch機能が登場">Anthropic Claude Proに「Research」機能が登場<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#anthropic-claude-proにresearch機能が登場" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Anthropicは、Claude Proプランに「Research」という新機能（ベータ版）を導入しました。これは統合されたリサーチ支援機能で、ユーザーがクエリを入力すると、直接的な回答ではなく、洞察や統合された情報を提供することを目的としているようです。</p>
<ul>
<li>ユーザーからは、このリサーチツールが単なる回答ではなく、実践的な洞察を通じて作業を改善する詳細なガイダンスを提供したとの声がある</li>
<li>自動的に3〜4のサブエージェントを展開し、多角的なアプローチでクエリに取り組むとの報告も</li>
</ul>
<h2 id="画像生成モデル-chroma-v34-リリース">画像生成モデル Chroma v34 リリース<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#画像生成モデル-chroma-v34-リリース" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>画像生成モデルChroma v34が、通常版と、より高解像度の画像を提供する「-detailed release」の2バージョンでリリースされました（<a href="https://huggingface.co/lodestones/Chroma/tree/main" class="external" target="_blank">Hugging Faceリンク<svg aria-hidden="true" class="external-icon" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>）。</p>
<ul>
<li>特に検閲されておらず、写実的なスタイルに偏っていないため、非写実的なアート生成やカスタマイズ性に優れていると評価されている</li>
<li>LoRAアダプターを詳細版で使用することで、品質がさらに向上するとの報告もある</li>
</ul>
<h2 id="aiによる経済格差と雇用喪失への懸念">AIによる経済格差と雇用喪失への懸念<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#aiによる経済格差と雇用喪失への懸念" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>AI技術の急速な進展は、社会経済的な課題に関する議論も活発化させています。</p>
<ul>
<li><strong>AIの高級品化</strong>: OpenAI、Anthropic、Googleなどの大手ベンダーが高性能LLMを有料プラン（月額100〜200ドル程度）の背後に置く傾向があり、オープンソースLLMも高性能化に伴いリソース要求が増大しています。これにより、高性能AIへのアクセス格差が広がる懸念が提起されています。</li>
<li><strong>Dario Amodei氏 (Anthropic CEO) の警鐘</strong>: AIによる広範な失業が労働者の経済的影響力を削ぎ、結果として民主主義を損ない、権力の集中を招く危険性を指摘しています。「『全てうまくいく』と言うだけでは防げない」と、積極的な対策の必要性を訴えています。</li>
<li><strong>元OpenAI AGI Readiness責任者の予測</strong>: Miles Brundage氏は、「2027年までに、コンピュータで実行可能なほぼ全ての経済的価値のあるタスクは、コンピュータによってより効果的かつ安価に実行されるようになるだろう」と述べています。ただし、これはあくまで技術的な可能性であり、実際の導入には組織の準備やデータインフラ、LLMの信頼性（ハルシネーション問題）など、多くの課題があるとの反論もあります。</li>
</ul>
<h2 id="aiの具体的な活用事例">AIの具体的な活用事例<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#aiの具体的な活用事例" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h3 id="chatgptによる医療記録の要約">ChatGPTによる医療記録の要約<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#chatgptによる医療記録の要約" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>あるユーザーは、病院での診察時の音声記録や文字起こしをChatGPTで処理し、遠隔地にいる家族のために分かりやすい要約を作成した事例を報告しています。同様に、MyChartなどの医療記録を要約して、がんの診断結果を伝えるといったユースケースも共有されました。公式の医療記録に基づいていれば精度は高いものの、Googleなどでダブルチェックすることが推奨されています。</p>
<h3 id="aiによる業務代替実験">AIによる業務代替実験<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#aiによる業務代替実験" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>ある物流会社の業務アシスタントの仕事を1週間AIツール（ChatGPT-4、Blackbox AI、Notion AI、Zapier+GPT）で代替する実験が行われました。結果として、定型的な反復作業（SOP作成、定型メール作成など）ではAIが最も効果を発揮しましたが、汎用的でない、文脈に沿った出力を得るためには人間による大幅な監督と文脈の注入が必要でした。この実験では約12時間の時間節約が実現しましたが、AIワークフローの調整と文脈付けにおける人間の役割の重要性が改めて浮き彫りになりました。</p>
<h2 id="discordでのai関連トピックサマリー">DiscordでのAI関連トピックサマリー<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#discordでのai関連トピックサマリー" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Discordコミュニティでも活発な議論が交わされています。以下はその一部です。</p>
<ul>
<li><strong>モデル開発の最前線</strong>: Googleの<strong>Gemini 2.5 Pro</strong>とその高性能版「<strong>Goldmane</strong>」がAiderベンチマークで好成績を収め、一般提供が近いとされています。OpenAIの<strong>o3 Pro</strong>は依然として謎が多く、初期の評判は芳しくないようです。Googleの未発表モデル「<strong>Kingfall</strong>」（おそらく<strong>DeepThink</strong>）が一時的にAI Studioに登場し、憶測を呼んでいます。日本からは<strong>Shisa-v2 405B</strong>が登場し、日本語・英語でGPT-4やDeepseekに匹敵する性能を謳っています。Alibaba Cloudの<strong>Qwen</strong>モデルは1MトークンのコンテキストウィンドウでDeepseek R1を凌駕するとされ、注目を集めています。</li>
<li><strong>エージェントAIの進化</strong>: OpenAIがTypeScript版の<strong>Agents SDK</strong>や<strong>RealtimeAgent機能</strong>をリリースし、エージェント開発を強化しています。LlamaIndexは、エージェント的RAGを用いた金融レポートチャットボット構築のColabを公開しました。複雑なエージェントフロー（例：gpt-41-miniを用いたElasticsearch DSLクエリ生成）や、エージェントの行動を制御する<strong>CursorRIPERフレームワーク</strong>、<strong>HTN (Hierarchical Task Networks)<strong>によるLLMエージェントのファインチューニングなどが議論されています。エージェント間通信プロトコルとしては、<strong>MCP (Meta-agent Communication Protocol)</strong> とGoogleの</strong>A2A (Agent-to-Agent) framework</strong> が比較検討されています。</li>
<li><strong>ハードウェアと最適化</strong>: NVIDIAの<strong>Blackwell</strong>アーキテクチャはCutlassサンプルで高い性能を示していますが（NVFP4で3.09 PetaFLOPS/s）、MXFP8/BF16の性能（0.23 PetaFLOPS/s）には疑問の声も。AMD <strong>MI300X</strong>では<code>rocprof</code>でのL2キャッシュヒット率読み取りエラーなどが報告されています。CUDA (<code>__syncthreads()</code>, <code>cuda::pipeline</code>) やROCmでのカーネル開発、<strong>Tinygrad</strong>でのLSTMレイヤーの遅さ、<strong>Torchtune</strong>でのIterable Datasetリファクタリングなどが話題です。</li>
<li><strong>最先端研究</strong>: LoRAやフルファインチューニングと比較して知識獲得効率が約4倍、破滅的忘却が30%少ないとされる新しい<strong>パラメータ効率の良いファインチューニング手法</strong>が注目されています。LLMのワールドモデルの脆弱性を突く「<strong>セマンティックウィルス</strong>」に関する論文や、テキストベースの自己対話を通じてLLMを進化させる研究、IBMによるオープンソースの<strong>責任あるプロンプティングAPI</strong>などが議論されました。</li>
<li><strong>エコシステムの動向</strong>: Anthropicが<strong>Claude 3.xモデルのキャパシティを大幅削減</strong>し、一部サービスに影響が出ています。OpenAIの<strong>TTS APIの価格設定</strong>に混乱が見られます。開発者向けツールとしては、Modal Labsの<strong>LLM Engineer’s Almanac</strong>（推論ベンチマーク集）、リポジトリと対話できる<strong>GitHub Chat</strong>、視覚・動画モデルの解釈ツールキット<strong>Prisma</strong>などが登場。オープンソースエージェントの<strong>OpenManus</strong>が<strong>agenticSeek</strong>に名称変更したことや、OpenAIが全てのChatGPTログ（削除済みチャットやAPIデータも含む）を保存するよう裁判所から命じられたとする報道がプライバシーに関する議論を呼んでいます。</li>
</ul>
<h2 id="まとめ">まとめ<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#まとめ" class="internal"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>今回もAI分野では、GoogleのDeepSearchスタックやNvidiaのNemotron推論モデルといった新しいツールの登場、Metaによる言語モデルの記憶メカニズム解明など、基礎研究から応用技術まで幅広い進展が見られました。動画生成AIのVeo 3やSoraはコンテンツ制作のあり方を大きく変えつつあり、ChatGPTのMemory機能やCodexの展開、ClaudeのResearch機能など、既存サービスの進化も続いています。</p>
<p>一方で、VLMのバイアス問題や、AIによる経済格差・雇用喪失といった社会的な課題への懸念も深まっています。医療記録の要約や業務アシストなど、具体的な活用事例も増えており、AIがより身近な存在になりつつあることを示しています。</p>
<p>Discordコミュニティでの活発な情報交換は、これらの技術革新がいかに速いペースで進んでいるかを物語っています。今後も目が離せない状況が続きそうです。</p></article><div class="page-footer"><div style="text-align:center;margin:3rem 0;"><a href="https://x.com/intent/tweet?text=%E3%80%90bot%E6%8A%95%E7%A8%BF%F0%9F%A4%96%E3%80%91AI%E6%9C%80%E6%96%B0%E5%8B%95%E5%90%91%20Google%20DeepSearch%E3%82%84Nvidia%E6%96%B0%E3%83%A2%E3%83%87%E3%83%AB%E7%99%BB%E5%A0%B4%20%7C%20%E3%81%BB%E3%81%93%E3%82%8A%E3%83%AD%E3%82%B0&amp;url=https%3A%2F%2Fblog.tachibanayu24.com%2Fnews%252Fai-latest-updates-jun25" target="_blank" rel="noopener noreferrer" class="twitter-share-button" style="box-shadow:0 4px 12px rgba(0, 0, 0, 0.15);display:inline-flex;align-items:center;padding:0.5rem 1rem;background-color:#8b7355;color:white;border-radius:9999px;text-decoration:none;font-size:0.875rem;gap:0.5rem;"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="currentColor"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"></path></svg>Share on X</a></div><div class="mobile-only"><div class="profile"><img src="https://pbs.twimg.com/profile_images/1582323777756876801/rtFFKM1E_400x400.jpg" alt="Profile"/><div class="profile-info"><p class="profile-name">たちばなゆうと</p><p class="profile-description">ソフトウェアエンジニアです。<br/>スタートアップや金融, 不動産, うさぎが好きです。</p><div class="profile-links"><a href="https://x.com/tachibanayu24" target="_blank" rel="noopener noreferrer"><svg fill="none" height="16" width="16" xmlns="http://www.w3.org/2000/svg" viewBox="0.254 0.25 500 451.95400000000006"><path d="M394.033.25h76.67L303.202 191.693l197.052 260.511h-154.29L225.118 294.205 86.844 452.204H10.127l179.16-204.77L.254.25H158.46l109.234 144.417zm-26.908 406.063h42.483L135.377 43.73h-45.59z" fill="#5d4a3c"></path></svg></a><a href="https://github.com/tachibanayu24" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" viewBox="0 0 256 249" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMinYMin meet"><g fill="#5d4a3c"><path d="M127.505 0C57.095 0 0 57.085 0 127.505c0 56.336 36.534 104.13 87.196 120.99 6.372 1.18 8.712-2.766 8.712-6.134 0-3.04-.119-13.085-.173-23.739-35.473 7.713-42.958-15.044-42.958-15.044-5.8-14.738-14.157-18.656-14.157-18.656-11.568-7.914.872-7.752.872-7.752 12.804.9 19.546 13.14 19.546 13.14 11.372 19.493 29.828 13.857 37.104 10.6 1.144-8.242 4.449-13.866 8.095-17.05-28.32-3.225-58.092-14.158-58.092-63.014 0-13.92 4.981-25.295 13.138-34.224-1.324-3.212-5.688-16.18 1.235-33.743 0 0 10.707-3.427 35.073 13.07 10.17-2.826 21.078-4.242 31.914-4.29 10.836.048 21.752 1.464 31.942 4.29 24.337-16.497 35.029-13.07 35.029-13.07 6.94 17.563 2.574 30.531 1.25 33.743 8.175 8.929 13.122 20.303 13.122 34.224 0 48.972-29.828 59.756-58.22 62.912 4.573 3.957 8.648 11.717 8.648 23.612 0 17.06-.148 30.791-.148 34.991 0 3.393 2.295 7.369 8.759 6.117 50.634-16.879 87.122-64.656 87.122-120.973C255.009 57.085 197.922 0 127.505 0"></path><path d="M47.755 181.634c-.28.633-1.278.823-2.185.389-.925-.416-1.445-1.28-1.145-1.916.275-.652 1.273-.834 2.196-.396.927.415 1.455 1.287 1.134 1.923M54.027 187.23c-.608.564-1.797.302-2.604-.589-.834-.889-.99-2.077-.373-2.65.627-.563 1.78-.3 2.616.59.834.899.996 2.08.36 2.65M58.33 194.39c-.782.543-2.06.034-2.849-1.1-.781-1.133-.781-2.493.017-3.038.792-.545 2.05-.055 2.85 1.07.78 1.153.78 2.513-.019 3.069M65.606 202.683c-.699.77-2.187.564-3.277-.488-1.114-1.028-1.425-2.487-.724-3.258.707-.772 2.204-.555 3.302.488 1.107 1.026 1.445 2.496.7 3.258M75.01 205.483c-.307.998-1.741 1.452-3.185 1.028-1.442-.437-2.386-1.607-2.095-2.616.3-1.005 1.74-1.478 3.195-1.024 1.44.435 2.386 1.596 2.086 2.612M85.714 206.67c.036 1.052-1.189 1.924-2.705 1.943-1.525.033-2.758-.818-2.774-1.852 0-1.062 1.197-1.926 2.721-1.951 1.516-.03 2.758.815 2.758 1.86M96.228 206.267c.182 1.026-.872 2.08-2.377 2.36-1.48.27-2.85-.363-3.039-1.38-.184-1.052.89-2.105 2.367-2.378 1.508-.262 2.857.355 3.049 1.398"></path></g></svg></a></div></div></div></div><div class="recent-notes mobile-only"><h3>最近の更新</h3><ul class="recent-ul"><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/chinese-models-jun25" class="internal">【bot投稿🤖】中国発新モデル AI開発競争と最新動向</a></h3></div><p class="meta"><time datetime="2025-06-17T03:55:26.000Z">2025年6月17日</time></p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/ai-latest-updates-jun25" class="internal">【bot投稿🤖】AI最新動向 Google DeepSearchやNvidia新モデル登場</a></h3></div><p class="meta"><time datetime="2025-06-05T05:52:28.000Z">2025年6月05日</time></p></div></li><li class="recent-li"><div class="section"><div class="desc"><h3><a href="../news/meeker-ai-deepseek-r1" class="internal">【bot投稿🤖】メアリーミーカー氏のAIレポートなど</a></h3></div><p class="meta"><time datetime="2025-05-31T03:49:43.000Z">2025年5月31日</time></p></div></li></ul><p style="text-align:right;padding-right:1rem;"><a href="../tags/" style="font-size:0.8rem;">さらに19件 →</a></p></div></div></div><div class="right sidebar"><div class="toc desktop-only"><button type="button" class="toc-header" aria-controls="toc-content" aria-expanded="true"><h3 style="font-size:0.8rem;color:var(--darkgray);">On This Page</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><ul class="toc-content overflow" id="list-1"><li class="depth-0"><a href="#ai技術の最新動向一挙まとめ-google-deepsearchからnvidia新モデルまで" data-for="ai技術の最新動向一挙まとめ-google-deepsearchからnvidia新モデルまで">AI技術の最新動向一挙まとめ Google DeepSearchからNvidia新モデルまで</a></li><li class="depth-1"><a href="#google-deepsearchスタックのオープンソース化" data-for="google-deepsearchスタックのオープンソース化">Google DeepSearchスタックのオープンソース化</a></li><li class="depth-1"><a href="#metaの論文言語モデルはどれだけ記憶するのか" data-for="metaの論文言語モデルはどれだけ記憶するのか">Metaの論文：言語モデルはどれだけ記憶するのか</a></li><li class="depth-1"><a href="#nvidia-nemotron-research-reasoning-qwen-15b" data-for="nvidia-nemotron-research-reasoning-qwen-15b">Nvidia Nemotron-Research-Reasoning-Qwen-1.5B</a></li><li class="depth-1"><a href="#vision-language-model-vlm-のバイアス" data-for="vision-language-model-vlm-のバイアス">Vision Language Model (VLM) のバイアス</a></li><li class="depth-1"><a href="#aiによる動画生成とコンテンツ制作の革新" data-for="aiによる動画生成とコンテンツ制作の革新">AIによる動画生成とコンテンツ制作の革新</a></li><li class="depth-2"><a href="#google-veo-3による低コストcm制作" data-for="google-veo-3による低コストcm制作">Google Veo 3による低コストCM制作</a></li><li class="depth-2"><a href="#microsoft-bingでのsora-ai動画生成" data-for="microsoft-bingでのsora-ai動画生成">Microsoft BingでのSora AI動画生成</a></li><li class="depth-1"><a href="#openaiの新たな動き" data-for="openaiの新たな動き">OpenAIの新たな動き</a></li><li class="depth-2"><a href="#ネイティブオーディオサポート付き新モデル" data-for="ネイティブオーディオサポート付き新モデル">ネイティブオーディオサポート付き新モデル</a></li><li class="depth-2"><a href="#chatgptのmemory機能が無料ユーザーにも" data-for="chatgptのmemory機能が無料ユーザーにも">ChatGPTのMemory機能が無料ユーザーにも</a></li><li class="depth-2"><a href="#codexがplusユーザーへ展開" data-for="codexがplusユーザーへ展開">CodexがPlusユーザーへ展開</a></li><li class="depth-1"><a href="#anthropic-claude-proにresearch機能が登場" data-for="anthropic-claude-proにresearch機能が登場">Anthropic Claude Proに「Research」機能が登場</a></li><li class="depth-1"><a href="#画像生成モデル-chroma-v34-リリース" data-for="画像生成モデル-chroma-v34-リリース">画像生成モデル Chroma v34 リリース</a></li><li class="depth-1"><a href="#aiによる経済格差と雇用喪失への懸念" data-for="aiによる経済格差と雇用喪失への懸念">AIによる経済格差と雇用喪失への懸念</a></li><li class="depth-1"><a href="#aiの具体的な活用事例" data-for="aiの具体的な活用事例">AIの具体的な活用事例</a></li><li class="depth-2"><a href="#chatgptによる医療記録の要約" data-for="chatgptによる医療記録の要約">ChatGPTによる医療記録の要約</a></li><li class="depth-2"><a href="#aiによる業務代替実験" data-for="aiによる業務代替実験">AIによる業務代替実験</a></li><li class="depth-1"><a href="#discordでのai関連トピックサマリー" data-for="discordでのai関連トピックサマリー">DiscordでのAI関連トピックサマリー</a></li><li class="depth-1"><a href="#まとめ" data-for="まとめ">まとめ</a></li><li class="overflow-end"></li></ul></div></div><footer style="text-align:center;"><hr/><p style="font-size:0.8rem;line-height:1;">Written by <a href="https://x.com/tachibanayu24" target="_blank" rel="noopener noreferrer">tachibanayu24</a> © 2025</p><p style="font-size:0.725rem;line-height:1.2;margin:0.25rem;">このブログは<a href="https://quartz.jzhao.xyz/" target="_blank" rel="noopener noreferrer">Quartz</a>をベースに作成しています。<a href="https://policies.google.com/technologies/partner-sites?hl=ja" target="_blank" rel="noopener noreferrer">Google Analytics</a>を使用してアクセス解析を行っています。</p><p style="font-size:0.725rem;line-height:1.2;margin:0.25rem;display:flex;gap:0.5rem;justify-content:center;"><a href="/index.xml" target="_blank" rel="noopener noreferrer">RSSフィード</a><a href="https://github.com/tachibanayu24/hokori-log" target="_blank" rel="noopener noreferrer">ソースコード</a></p></footer></div></div></body><script type="application/javascript">function o(){let t=this.parentElement;t.classList.toggle("is-collapsed");let e=t.classList.contains("is-collapsed")?this.scrollHeight:t.scrollHeight;t.style.maxHeight=e+"px";let c=t,l=t.parentElement;for(;l;){if(!l.classList.contains("callout"))return;let i=l.classList.contains("is-collapsed")?l.scrollHeight:l.scrollHeight+c.scrollHeight;l.style.maxHeight=i+"px",c=l,l=l.parentElement}}function n(){let t=document.getElementsByClassName("callout is-collapsible");for(let s of t){let e=s.firstElementChild;if(!e)continue;e.addEventListener("click",o),window.addCleanup(()=>e.removeEventListener("click",o));let l=s.classList.contains("is-collapsed")?e.scrollHeight:s.scrollHeight;s.style.maxHeight=l+"px"}}document.addEventListener("nav",n);
</script><script type="module">function f(i,e){if(!i)return;function r(o){o.target===this&&(o.preventDefault(),o.stopPropagation(),e())}function t(o){o.key.startsWith("Esc")&&(o.preventDefault(),e())}i?.addEventListener("click",r),window.addCleanup(()=>i?.removeEventListener("click",r)),document.addEventListener("keydown",t),window.addCleanup(()=>document.removeEventListener("keydown",t))}function y(i){for(;i.firstChild;)i.removeChild(i.firstChild)}var h=class{constructor(e,r){this.container=e;this.content=r;this.setupEventListeners(),this.setupNavigationControls(),this.resetTransform()}isDragging=!1;startPan={x:0,y:0};currentPan={x:0,y:0};scale=1;MIN_SCALE=.5;MAX_SCALE=3;cleanups=[];setupEventListeners(){let e=this.onMouseDown.bind(this),r=this.onMouseMove.bind(this),t=this.onMouseUp.bind(this),o=this.resetTransform.bind(this);this.container.addEventListener("mousedown",e),document.addEventListener("mousemove",r),document.addEventListener("mouseup",t),window.addEventListener("resize",o),this.cleanups.push(()=>this.container.removeEventListener("mousedown",e),()=>document.removeEventListener("mousemove",r),()=>document.removeEventListener("mouseup",t),()=>window.removeEventListener("resize",o))}cleanup(){for(let e of this.cleanups)e()}setupNavigationControls(){let e=document.createElement("div");e.className="mermaid-controls";let r=this.createButton("+",()=>this.zoom(.1)),t=this.createButton("-",()=>this.zoom(-.1)),o=this.createButton("Reset",()=>this.resetTransform());e.appendChild(t),e.appendChild(o),e.appendChild(r),this.container.appendChild(e)}createButton(e,r){let t=document.createElement("button");return t.textContent=e,t.className="mermaid-control-button",t.addEventListener("click",r),window.addCleanup(()=>t.removeEventListener("click",r)),t}onMouseDown(e){e.button===0&&(this.isDragging=!0,this.startPan={x:e.clientX-this.currentPan.x,y:e.clientY-this.currentPan.y},this.container.style.cursor="grabbing")}onMouseMove(e){this.isDragging&&(e.preventDefault(),this.currentPan={x:e.clientX-this.startPan.x,y:e.clientY-this.startPan.y},this.updateTransform())}onMouseUp(){this.isDragging=!1,this.container.style.cursor="grab"}zoom(e){let r=Math.min(Math.max(this.scale+e,this.MIN_SCALE),this.MAX_SCALE),t=this.content.getBoundingClientRect(),o=t.width/2,n=t.height/2,c=r-this.scale;this.currentPan.x-=o*c,this.currentPan.y-=n*c,this.scale=r,this.updateTransform()}updateTransform(){this.content.style.transform=`translate(${this.currentPan.x}px, ${this.currentPan.y}px) scale(${this.scale})`}resetTransform(){this.scale=1;let e=this.content.querySelector("svg");this.currentPan={x:e.getBoundingClientRect().width/2,y:e.getBoundingClientRect().height/2},this.updateTransform()}},C=["--secondary","--tertiary","--gray","--light","--lightgray","--highlight","--dark","--darkgray","--codeFont"],E;document.addEventListener("nav",async()=>{let e=document.querySelector(".center").querySelectorAll("code.mermaid");if(e.length===0)return;E||=await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.esm.min.mjs");let r=E.default,t=new WeakMap;for(let n of e)t.set(n,n.innerText);async function o(){for(let s of e){s.removeAttribute("data-processed");let a=t.get(s);a&&(s.innerHTML=a)}let n=C.reduce((s,a)=>(s[a]=window.getComputedStyle(document.documentElement).getPropertyValue(a),s),{}),c=document.documentElement.getAttribute("saved-theme")==="dark";r.initialize({startOnLoad:!1,securityLevel:"loose",theme:c?"dark":"base",themeVariables:{fontFamily:n["--codeFont"],primaryColor:n["--light"],primaryTextColor:n["--darkgray"],primaryBorderColor:n["--tertiary"],lineColor:n["--darkgray"],secondaryColor:n["--secondary"],tertiaryColor:n["--tertiary"],clusterBkg:n["--light"],edgeLabelBackground:n["--highlight"]}}),await r.run({nodes:e})}await o(),document.addEventListener("themechange",o),window.addCleanup(()=>document.removeEventListener("themechange",o));for(let n=0;n<e.length;n++){let v=function(){let g=l.querySelector("#mermaid-space"),m=l.querySelector(".mermaid-content");if(!m)return;y(m);let w=c.querySelector("svg").cloneNode(!0);m.appendChild(w),l.classList.add("active"),g.style.cursor="grab",u=new h(g,m)},M=function(){l.classList.remove("active"),u?.cleanup(),u=null},c=e[n],s=c.parentElement,a=s.querySelector(".clipboard-button"),d=s.querySelector(".expand-button"),p=window.getComputedStyle(a),L=a.offsetWidth+parseFloat(p.marginLeft||"0")+parseFloat(p.marginRight||"0");d.style.right=`calc(${L}px + 0.3rem)`,s.prepend(d);let l=s.querySelector("#mermaid-container");if(!l)return;let u=null;d.addEventListener("click",v),f(l,M),window.addCleanup(()=>{u?.cleanup(),d.removeEventListener("click",v)})}});
</script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="../postscript.js" type="module"></script></html>