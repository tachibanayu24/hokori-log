{"dev/Obsidian-vaultの一部のディレクトリだけをQuartzで公開する":{"slug":"dev/Obsidian-vaultの一部のディレクトリだけをQuartzで公開する","filePath":"dev/Obsidian vaultの一部のディレクトリだけをQuartzで公開する.md","title":"Obsidian vaultの一部のディレクトリだけをQuartzで公開する","links":[],"tags":["Obsidian"],"content":"何回目かわからないけどブログを作りました。\n試したい技術が現れるたびにブログを作っている気がしますが、今回はちゃんと更新していけるように頑張ります。\nこのブログは、Obsidianのvault（保管庫 ローカルのディレクトリ）の一部のディレクトリをブログ記事として切り出してSSGで記事化し公開する構成になっているので、その説明をします。\nQuartz自体の説明はここではしません。\nこの構成のメリット\npushごとに公開\nObsidianのノートを更新してpushするたびにデプロイjobが実行されるので公開が楽です。\nプライベートなvaultと同一リポジトリ内で独立\n通常、QuartzなどのSSGでブログを作るときは、SSGリポジトリの内部にObsidianのvaultを配置することになると思います。\nその場合、プライベートなvaultとは独立することになりますが、管理が面倒ですし、LLMの恩恵を受けながら記事を書きたい場合は同一のリポジトリで管理して、同じ場所でドキュメントをindex化して活用したいです。\nそういったことができるようになります。\n構成\nリポジトリは2つ登場します。\n\nobsidian-vault\n\nプライベートなObsidian vaultで普通にドキュメント管理として使う\n_published ディレクトリ内のドキュメントのみブログ記事としてビルドして公開したい\n\n\nobsidian-blog\n\nブログのSSGやUIなどを管理する（つまりこのブログの本体）\nソースコードはこちら\n\n\n\nアプローチは、obsidian-vaultの _published ディレクトリ内に変更があったときにGitHub Actionsでeventをdispatchしてobsidian-blog側のGitHub Actionsのトリガーにし、obdsidian-blogではobsidian-vaultをcloneしてきて _published 内のみSSGで記事を生成して公開するというものです。\nローカルでは obsidian-blog の content で obsidian-vault のシンボリックリンクを貼ればローカルでもプレビューできます。\nsequenceDiagram\n    participant OV as obsidian-vault\n    participant GA1 as GitHub Actions\n    participant GB as obsidian-blog\n    participant GA2 as GitHub Actions\n    participant GH as GitHub Pages\n\n    OV-&gt;&gt;GA1: _published/に差分あり\n    GA1-&gt;&gt;GB: vault-updated event\n    GB-&gt;&gt;GA2: triggered\n    GA2-&gt;&gt;OV: クローン\n    GA2-&gt;&gt;GA2: Quartz 4でビルド\n    GA2-&gt;&gt;GH: デプロイ\n\nDeploy用yml\nこれで _published に差分があったときに obsidian-blog のGAが受け取れるeventをdispatchします。\nDISPATCH_TOKEN は、obsidian-blogの contents:read,write 権限を持つ personal access token(PAT)です。\nobsidian-vault/.github/workflows/deploy.ymlname: Trigger Blog Deploy on Published Changes\n \non:\n  push:\n    branches:\n      - main\n    paths:\n      - &#039;_published/**/*.md&#039;\n \njobs:\n  dispatch:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Trigger deployment in obsidian-blog repo\n        uses: peter-evans/repository-dispatch@v3\n        with:\n          token: ${{ secrets.DISPATCH_TOKEN }}\n          repository: tachibanayu24/obsidian-blog\n          event-type: vault-updated\nこれで obsidian-vault から受け取ったeventをトリガーにしてデプロイを実行します。 obsidian-blog でmainブランチにpushしたときにも実行します。\nVAULT_ACCESS_TOKEN は、obsidian-vaultの contents:read 権限を持つ personal access token(PAT)です。\nobsidian-blog/.github/workflows/deploy.ymlname: Deploy Blog\n \non:\n  push:\n    branches:\n      - main\n \n  repository_dispatch:\n    types: [vault-updated] # obsidian-vaultの `_published` が更新されたらdispatchされる\n \npermissions:\n  contents: write\n \njobs:\n  build_and_deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout obsidian-blog Repo\n        uses: actions/checkout@v4\n        with:\n          path: obsidian-blog\n \n      - name: Checkout obsidian-vault Repo (to temp location)\n        uses: actions/checkout@v4\n        with:\n          repository: tachibanayu24/obsidian-vault\n          path: vault-temp\n          token: ${{ secrets.VAULT_ACCESS_TOKEN }}\n \n      - name: Prepare content directory\n        run: mkdir -p obsidian-blog/content\n \n      - name: Copy published content\n        run: |\n          if [ -d &quot;vault-temp/_published&quot; ] &amp;&amp; [ &quot;$(ls -A vault-temp/_published)&quot; ]; then\n            cp -r vault-temp/_published/* obsidian-blog/content/\n          else\n            echo &quot;Warning: vault-temp/_published directory is empty or does not exist.&quot;\n          fi\n \n      # attachmentsは通常 `_published` には配置しないので、画像など正しく表示するためにこれもコピーする\n      - name: Copy attachments to content root\n        run: |\n          if [ -d &quot;vault-temp/_config/attachment&quot; ] &amp;&amp; [ &quot;$(ls -A vault-temp/_config/attachment)&quot; ]; then\n            cp -r vault-temp/_config/attachment/* obsidian-blog/content/\n          else\n            echo &quot;Info: vault-temp/_config/attachment directory is empty or does not exist.&quot;\n          fi\n \n \n      - name: Setup Node, Install, Build\n        working-directory: obsidian-blog\n        env:\n          NODE_ENV: production\n        run: |\n          npm ci\n          npx quartz build\n \n      - name: Deploy to GitHub Pages\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./obsidian-blog/public\n          cname: blog.tachibanayu24.com\nおわり\nこれで単一vault内でプライベートな領域と公開用の領域で分けることができました。"},"dev/auto-article-publisher":{"slug":"dev/auto-article-publisher","filePath":"dev/auto-article-publisher.md","title":"全自動でブログの記事を生成して公開するようにしてみるテスト","links":[],"tags":["LLM","Firebase"],"content":"生成AI周りの活況や趨勢の変化がすごく、情報のキャッチアップがだいぶしんどいですよね。私は技術者ですが、役割上ビジネス的なユースケース・プロダクトにもついていかないといけないのでなかなか大変になってきました。\nそこで、平凡な発送ですが、信頼できる情報ソースと思うメディアのRSSを監視し、更新されたら自動でLMMに記事化させ、せっかくなのでこのブログにpublishするbotを実装して放流してみました。\n実際にbotにより投稿された記事は今のところ以下の２つです。\n\n【bot投稿🤖】OpenAIの新主力モデルGPT4.1 API提供開始 | ほこりログ\n【bot投稿🤖】最新AIニュース Veo 2とKling 2が一般公開 GPT-4.1も | ほこりログ\n\nそれなりに良い出来なのではないかと思っています。\n構成\nZapierやDifyなどワークフローを簡単に構成できるサービスを使いたかったのですが、使用できるファウンデーションモデルが限定的であったり、結局jsを実行するActionを指定しないといけないとかで面倒だったので、シンプルにサーバレス関数を実装しています。\n普通のことをやっています。\n\n{duration} 分に1度、関数をトリガーする\n事前に指定してあるすべてのRSSフィードをfetchしてparseする\n\n今回は簡易的に、pubDateが {duration} より新しいもののみ対象とする\n\n\n2で得た更新分のURLをfetchして、得られたHTMLから @mozilla/readability でコンテンツを抽出する\n3の結果と、過去の自分の記事、promptを与えてgemini 2.5 Proで記事のメイン部分とslugを生成させる\n4の結果にタグや作成日、slugなどを所定のフォーマットで保管する\n5で得た記事ファイル全体を、ブログのコンテンツを管理するprivate repositoryにpushする\n\npushでSSGのbuildを実行してdeployするようになっている(詳細)\n\n\n\n実装\nコードベースはこちらです。\nGitHub - tachibanayu24/rss-to-blog-publisher\nプロンプトはこまめに調整すると思うのでブログには書かないですが、現時点ではこの部分に記述しています。\n改善点\nやってみて思ったことですが、こういうユースケースでは、一度に必要なコンテキストをまとめて渡してほしいものを生成し切るようにするのではなく、もう少し分割的にLLMを呼び出したほうがいいかもしれないですね。\n今回の例では、「指示、過去記事（筆者の論調を真似るため）、記事の元ネタ」を渡して記事化までいっきにするのではなく、以下のようにステップが踏めたはずです。\n\n指示、記事の元ネタを渡して、まずはあまり情報を剥落させずにまとめさせる\n指示、過去記事を渡して、1の内容を筆者になりきって記事として仕上げさせる\n\n関数みたいに単一責任的に処理ステップを分割するということです。\nもちろん、関数がそうであるべき理由とは別の理由でです。LLMが進化して長いコンテキストを扱えるようになってきていますが、長過ぎるコンテキストを渡すとその中間部分はあまり使用されず、性能が劣化することはよく知られています。\n\n\nChanging the location of relevant information (in this case, the position of the passage that answers an input question) within the language model’s input context results in a U-shaped performance curve—models are better at using relevant information that occurs at the very beginning (primacy bias) or end of its input context (recency bias), and performance degrades significantly when models must access and use information located in the middle of its input context.\n\nLost in the Middle: How Language Models Use Long Contexts\n\n\nこのあたりもっと深堀りする価値があるなと思いました。別の記事でやるかも。\n今後の運用\nという感じで、1~2日に1回くらい、botが自動でAIのニュース（技術的関心が中心）を投稿するようになっています。\nただ、アウトプットの品質を見て、botの時点ではドラフト状態にして、人間が必ずレビューするようにしたりはするかもしれないです。ネットにゴミを増やすつもりは全然ないので。"},"dev/firebase-studio-testplay":{"slug":"dev/firebase-studio-testplay","filePath":"dev/firebase-studio-testplay.md","title":"ブラウザベースのAI統合開発環境 Firebase Studio を触ってみる","links":[],"tags":["Firebase","CodingAgent","LLM"],"content":"2025/4/9、Firebase Studioのプレビュー版がローンチされました。\n早速触ってみたので感想など書いていきます。\nFirebase Studioとは？\nIntroducing Firebase Studio で詳しく紹介されています。\n主な機能\n\n\n自然言語からのプロトタイプ作成\n\nプロンプト、画像、図面からネイティブアプリやWebアプリケーションを構築\nGemini APIキーは対話的に作成して設定できる\n\n\n\nAIチャットによる迅速な反復\n\nGemini in Firebaseとのチャットで、ユーザー認証の追加、レイアウト変更、UI改善などを実現\nコードベースを理解した上で自然言語の指示に基づいて更新\n\n\n\nCodeOSSベースのIDE\n\nコード補完、デバッグ、説明、ターミナルアクセスなどのGeminiコード支援\nFirebaseサービスとの統合\n\n\n\nマルチデバイスプレビュー\n\nWebプレビュー用の公開URL生成\nQRコードによるモバイルデバイスでのプレビュー\n\n\n\nワンクリックデプロイ\n\nFirebase App Hostingを活用した簡単デプロイ\nビルド、CDN、サーバーサイドレンダリングを自動処理\n\n\n\nリアルタイム共同作業\n\nワークスペース全体をURLで共有\n同じ環境内でのリアルタイム共同作業\n\n\n\n利用可能なプラン\n\n無料プラン: 3つのワークスペース\nGoogle Developer Program: 10のワークスペース\nPremium Google Developer Program: 30のワークスペース\n\n一部の統合（Firebase App Hostingなど）には課金アカウントが必要な場合があります。\n触ってみる\nApp Prototyping エージェントを使用してフルスタック ウェブアプリを開発、公開、モニタリングする  |  Firebase Studio にプロンプトが紹介されているので、これのとおりにプロトタイプを構築してみます。\n食品の画像を与えて、それがなんという食品なのかを判定し、レシピを教えてくれるアプリケーションですね。\n\n\n                  \n                  プロンプト \n                  \n                \n\nBuild a web app that can identify food products from an uploaded picture or\nin-browser camera. The app should provide a recipe that contains the\nidentified ingredients. 日本語で構築して\n\n\n完成品は以下のような感じです。\n\nとりあえずこれは一発でできました。\n初回の実行後には、自然言語で反復するのに特化したプロトタイパービューと、実際のコードを参照してデバッグできるコードビューで切り替えることができます。\n\nIDEの方はCodeOSSベースで、プレビューとGeminiとの会話が搭載されています。アンドロイドアプリもエミュレートしてこのようにプレビューできるらしいです。\n感想\n簡単なプロトタイピングはかなり楽ちんにできるので、特定のユースケースを検証するためにノーコードでアプリケーションを構築するとかのニーズは十分満たしそうに見えます。\nただし、Firebase Studioという命名とは裏腹に、FirestoreとかStorageをセットアップして接続して…とかはできないので、その部分は自分でやって上げる必要があるのがちょっと面倒な感じ。それ以外の品質とかは既存のコーディングエージェントと大差ない印象です。\n少し高度なことをやろうとするとエラーも多いです。stack traceとかみて修正を試みてはくれるんですが、そんなに解決しないですね…\n\n良かったところ\n\n3つまで無料\nブラウザベースのIDEがすぐに立ち上がるのでどの環境でも手軽に扱える\nGemini APIキーをボタン一つで作成して利用してくれる\nVueやNextなどテンプレートを選択できるので、簡単に技術スタックをざっくりと指定できる\nAI機能部分はgenkitを用いてワークフローを必ず構築するようになっているっぽい\n\n入出力のzodスキーマとかも\n\n\n\n\n今一つなところ\n\nアウトプットの精度に驚きは特に無い\n\n既存のコーディングエージェントと比べて優れているとは思わない\n\n\nFirestoreなど、Firebaseのサービスの構築もしてくれるとかではない\n\nFirestoreで実行履歴を永続化して、とかの指示をすると、コードはそれっぽくやってくれるが各サービスを有効化したりkeyを自動で入力してくれたりとかはまだない感じ\nhostingで公開するくらい\n\n\n\n\n"},"dev/vibe-coding-with-gpt-4_1":{"slug":"dev/vibe-coding-with-gpt-4_1","filePath":"dev/vibe-coding-with-gpt-4_1.md","title":"GPT-4.1をCursorのAgent Modeで使ってみる","links":[],"tags":["CodingAgent","LLM"],"content":"OpenAIがGPT-4.1をリリースし、すぐさまCursorは「肌感を掴んでもらうために当面は無料で提供します」と利用可能のモデルにこれを追加しました。(Xのポストを参照)\nOpenAIの発表によると、コーディング能力が向上したり長文コンテキストの処理能力や理解力が改善したということです。さっそくCursorで触ってみます。\nVibe codingやるぞ\n対話1: とりあえず作り切らせる\nごく簡単なCRUDを持つアプリケーションを要求します。今回作るのは旅行とかで作成する持ち物リストを管理するためのアプリケーションです。\n以下のプロンプトから開始します。\nプロンプト旅行の持ち物リストを管理するアプリケーションを作ってみて。とりあえず最後まで作り切ってみて。\n  \n- ログイン機能は不要  \n- ユーザーは持ち物の追加、削除、編集ができる  \n- データは永続化されるが、デモアプリなので簡易的な手段を選択して良い（SQLiteなど）  \n- テンプレートを追加できる（財布など行き先に関係なく必ず持っていくようなものをまとめることができる）  \n- カバンに入れたかどうかの状態をcheckboxで管理できる  \n- おしゃれでモダンなUI\nで、特に躓くことなくここまではコーディングしてくれました。\n\nバックエンドはexpress, sqlite3、フロントエンドはvite, typescript, react, emotion, muiというスタックを選択したようです。\nnpm create vite@latest . -- --template react-ts でプロジェクトを開始した際に作成された index.css により color-schema が dark になっており、そのせいで見づらいようです。\nしかしちゃんとデータの永続化はできていますね。（画像の入力値はこちらで入れたもの）\nプロンプト&gt; すべてのテーブルの中身を標準出力して\n \n全テーブル（items, templates, template_items）の中身は以下の通りです。\n \n---\n \n### items テーブル\n \n| id | name | packed |\n|----|-----------|--------|\n| 3 | test | 0 |\n| 4 | hogehoge | 0 |\n \n### templates テーブル\n \n| id | name |\n|----|----------------|\n| 1 | testとhogehoge |\n \n### template_items テーブル\n \n| template_id | name | packed |\n|-------------|-----------|--------|\n| 1 | test | 0 |\n| 1 | hogehoge | 0 |\n \n対話2: ブラッシュアップする\nプロンプトちゃんと動いているようです。以下についてブラッシュアップしてください。  \n  \n- create viteしたときに生成された余計なファイルが残っています\n\t- 不要なものは消してください\n\t- 特に、index.cssが影響して、OSがダークモードのユーザーは視認性がとても悪いです  \n- UIがダサすぎるのでもっとモダンなwebサービスっぽくして  \n- タイトルをもっといい感じに考えて\n結果が以下の通り。割と良いのではないでしょうか？\n\n対話3: ちょっとだけ難しそうなことを言ってみる\n限定的なコンテキストしか持たないのでしょうがないんですが、他のシステムに依存するとうまくいかないことが多いので、geminiのAPIを利用するように促してみます。\nプロンプトbackend/.env に、 GEMINI_API_KEY という命名でgeminiのAPIキーを追加しました。  \nこれで、行き先と泊数を入力したら、持ち物リストを提案してくれて、それを編集して適用できるような機能を追加してください。\n結果は以下。一発では無理だったのでここからデバッグさせます。\n\nデバッグのやり取りは何往復もしたので載せませんが。。\n流れとしては、\n\nbackendの必要な依存関係をインストールしていなかった\ngeminiの存在しないモデルを指定していた\ngeminiに与えるプロンプトがおかしかった\n\nという感じでした。2の解決は結局できず、人間が修正しました。\n対話3の完成形は以下のとおりです。良いのではないでしょうか。\n　\nまだClaudeやgeminiの最上位と比較してどうかは評価しきれませんが、そんなに悪くなさそうなのでちょっと使ってみようと思います。\n最終形のコードベースはこちらです。\nGitHub - tachibanayu24/gpt-4.1-test\n（おまけ）うざかったところ\n今回 cursor ruleとか特に設定せずに素手でやったので、ちゃんとやれば防げるんでしょうけど。\n\n人間が修正したところを何回も戻そうとする\nすぐ迷子になって cd: no such file or directory\nnodeをkillすな！\n\n"},"finance/2025-04-06-米国株の現在地の確認":{"slug":"finance/2025-04-06-米国株の現在地の確認","filePath":"finance/2025-04-06 米国株の現在地の確認.md","title":"2025-04-06 米国株の現在地の確認","links":[],"tags":["株式"],"content":"値動きが激しいので現在の米国株（S&amp;P500）の状況を確認します。\nあんまりこの手の話題で自分の意見を書くのもどうかなと思うので、客観的な事実だけをまとめます。（市場の予想は一切しません）\n最近の主な出来事\nトランプ氏、相互関税を発表　最大50％で日本は24％ - BBCニュース\n\n\n                  \n                  AIによる要約 \n                  \n                \n\nトランプ米大統領が全輸入品への新関税計画を発表。10%基本税に加え、「最悪の違反者」に追加関税。日本には24%が課される。中国やEUにも高関税。「経済的独立宣言」とし、世界経済への影響が懸念されている。\n\n\n中国が報復関税を発表、米株式市場はパンデミック以来の大幅安に - BBCニュース\n\n\n                  \n                  AIによる要約 \n                  \n                \n\n中国が米国の関税に対抗し、全米輸入品へ34%の報復関税を発表。これを受け欧米株価は急落、米主要指数は5%超下落しパンデミック以来最悪の週となった。貿易戦争激化と世界経済への悪影響が懸念される。\n\n\nチャート\nS&amp;P500の直近高値は6147USD、現在の株価は5074USDです。\n2/19の高値から1ヶ月半ほどしか経過していませんが、17.5%ほど下がっています。\n調整局面の目安は10%、弱気相場の目安は20%なので、今は調整局面です。\nちなみにナスダックとラッセル2000はすでに弱気相場入りしています。\n月足では3月に -5.75% と大きく下落しましたが、現時点で4月もすでに -9.58% 下げています。\n\n日足では200日移動平均線で弾かれたあとに、2日連続で出来高を伴って窓を開けて大きく下落しています。\n\n金曜日は広範囲の銘柄が売られたのでヒートマップは真っ赤になっています。\n\n出典: FINANCIAL VISUALIZATIONS\nセンチメント\n恐怖指数(VIX)\nVIXはこの急落を受けて45.3まで急騰しました。\n直近でVIXが40を超えたときのイベントは以下のとおりです。\n\n2024年8月\n\n日経平均株価4451円安　下げ幅ブラックマンデー超え最大 - 日本経済新聞\n\n\n2020年3月〜4月\n\nコロナウイルスの世界的流行\n\n\n\nつまり、一瞬のパニック売があった2024年8月を除けばコロナウイルス流行時以来の水準です。\n\nFear &amp; Greed Index\n現在値は 4 で Extreme Fearです。\n\n出典: CNN Business\nプットコールレシオ\nプットオプションとコールオプションの比で表されるプットコールレシオは現在 1.07です。（IBD）\n1を超えているので、弱気が優勢になってきているということが言えます。\n来週のイベント\n\n4/9\n\nデルタ航空（DAL）決算\n\n\n4/10\n\n米国 消費者物価指数（CPI・コアCPI）\n米国 新規失業保険申請件数\n\n\n4/11\n\n米国 生産者物価指数（PPI）\n米国 ミシガン大学消費者信頼感指数\nJPモルガン（JPM）決算\nウェルズ・ファーゴ（WFC）決算\n\n\n\n再来週（4/14~）は小売売上高、鉱工業生産指数やゴールドマン・サックス、バンク・オブ・アメリカ、ユナイテッドヘルス、ネットフリックスなどの決算があります。\n各国の米国関税に対するリアクションもどんどん出てくるかもしれません。"},"index":{"slug":"index","filePath":"index.md","title":"TOP","links":[],"tags":[],"content":"たちばなゆうとのブログです。\n主にソフトウェア、LLM、スタートアップビジネス、ファイナンスなどの話題の記事を書くつもりです。"},"misc/chiipoke-number-scale":{"slug":"misc/chiipoke-number-scale","filePath":"misc/chiipoke-number-scale.md","title":"ちいぽけにおける数字の扱い方に関する考察","links":[],"tags":["数学","雑学"],"content":"ちいかわぽけっと（ちいぽけ）がサイバーエージェントグループの applibot社からリリースされました。\nスマホのゲームはあんまりやらないのですが、初めてのちいかわのちゃんとしたスマホゲームということでちょっとプレイしています。数字の扱い方がヤバすぎるのでどうなっているのか少し考えてみようと思います。\n単位の表記\n\n出典: ちいかわぽけっと\n画面上に o とか h とかのアルファベットがありますが、これは桁数を表現しています。\nちいぽけにおける所持金や攻撃力、体力などのパラメータは非線形に急激に増加していき、 k = 10^3 とかではなく、 a = 10^3, b=10^6, c=10^9, ... といった具合にオーダーが増加していきます。\nこれを一般項にすると以下のように言えます。\n\nS: abなどのアルファベット\nn(S): aから数えたときのアルファベットの登場順\nL:  Sの文字数\ns_i: Sの左から i 番目の文字(abcのとき、 s_2 は b)\nval(s_i): 文字のインデックス(a=0, b=1, …, z=25)\n\nとすると、\nアルファベットS が何番目の記号かを示す n(S)\nn(S) = \\left( \\sum_{k=1}^{L-1} 26^k \\right) + \\left( \\sum_{i=1}^{L} \\mathrm{val}(s_i) \\times 26^{L-i} \\right) + 1\n一般的な表現 V\n\\mathrm{V} = X \\times 10^{3 \\times n(S)}\n現時点で確認されているのは aa とアルファベット二桁までなので、最低限ここまではあるだろうと思われるzzをこれに適用します。\nS = zz , L = 2 , s_1 = z , s_2 = z とすると、zzは702番目の記号とわかります。\nn(zz) = \\left( \\sum_{k=1}^{2-1} 26^k \\right) + \\left( \\sum_{i=1}^{2} val(s_i) \\times 26^{2-i} \\right) + 1\n= \\left( 26^1 \\right) + \\left( val(s_1) \\times 26^{2-1} + val(s_2) \\times 26^{2-2} \\right) + 1\n= 26 + (25 \\times 26 + 25 \\times 1) + 1\n= 702\n702番目の記号zzは、 3×n(zz)=3×702=2106 より 10^{2106} であるとわかります。天文学的という形容では全く追いつかないくらい大きな値です。\n論理的な表現\n一般的な64ビットの倍精度浮動小数点数（ double 型）では、大体  10^{\\pm308} くらいの非常に大きな（or 小さな）数を表現できますが、ちいぽけには足りません。\nしかしちいぽけはゲーム設計上、非常に大きな値と相対的に小さな値の演算は重要ではないはずなので数字の精度はざっくりで良いはずです。\nどんなふうに扱っているのかを想像してみます。\n浮動小数点数の応用を考えてみます。浮動小数点数では、数を「仮数部（有効桁数を持つ部分）」と「指数部（10の何乗かを示す部分）」に分けて表現します。\nこの構造を拡張して考えるとさらに大きな値も扱うことができそうです。ここで仮数部と指数部を以下のように定義してみます。\n\n仮数部: ゲームプレイに必要な精度のみ保持する\n\ne.g. 5.25 のような2桁程度\n\n\n指数部: 「10の何乗か」を示す部分\n\n整数型など\n\n\n\nこうすると以下のようになります。\n\n5.2aa (5.2×10^81) は、内部的に { 仮数部: 5.2, 指数部: 81 }\n1.0zz (1.0×10^2106) は、内部的に { 仮数部: 1.0, 指数部: 2106 }\n\nといった形でデータを保持できるはずです。\njavascriptで表現してみます。負の値は今のところ見たことがないので考慮しません。\nclass ChiipokeNumber {\n  /**\n   * @param {number} mantissa 仮数部\n   * @param {number} exponent 指数部\n   */\n  constructor(mantissa = 0, exponent = 0) {\n    this.mantissa = Number(mantissa);\n    this.exponent = Number(exponent);\n    this.normalize();\n  }\n \n  /**\n   * 数値を正規化する（仮数部が1以上10未満になるようにする）\n   * @method normalize\n   * @returns {void}\n   */\n  normalize() {\n    if (this.mantissa === 0) {\n      this.exponent = 0;\n      return;\n    }\n    while (this.mantissa &gt;= 10) {\n      this.mantissa /= 10;\n      this.exponent++;\n    }\n    while (this.mantissa &lt; 1 &amp;&amp; this.mantissa !== 0) {\n      this.mantissa *= 10;\n      this.exponent--;\n    }\n  }\n \n  /**\n   * @param {ChiipokeNumber} num\n   */\n  multiply(num) {\n    const newMantissa = this.mantissa * num.mantissa;\n    const newExponent = this.exponent + num.exponent;\n    return new ChiipokeNumber(newMantissa, newExponent);\n  }\n \n  /**\n   * @param {ChiipokeNumber} num\n   */\n  add(num) {\n    // 片方の値が相対的に非常に大きい場合は小さい方を無視\n    if (Math.abs(this.exponent - num.exponent) &gt; 16) {\n      return this.exponent &gt; num.exponent ? new ChiipokeNumber(this.mantissa, this.exponent) : new ChiipokeNumber(num.mantissa, num.exponent);\n    }\n  \n    let newMantissa;\n    let newExponent;\n    if (this.exponent &gt;= num.exponent) {\n      newExponent = this.exponent;\n      newMantissa = this.mantissa + num.mantissa / (10**(this.exponent - num.exponent));\n    } else {\n      newExponent = num.exponent;\n      newMantissa = num.mantissa + this.mantissa / (10**(num.exponent - this.exponent));\n    }\n    return new ChiipokeNumber(newMantissa, newExponent);\n  }\n \n  /**\n   * アルファベット表記を得る\n   * @method getNotationString\n   * @param {number} n   単位インデックス (a=1, aa=27, ...)\n   * @returns {string} アルファベット表記\n   */\n  static getNotationString(n) {\n    // 0以下の場合はアルファベットなし\n    if (n &lt;= 0) return &quot;&quot;;\n \n    const alphabet = &quot;abcdefghijklmnopqrstuvwxyz&quot;;\n    let L = 0; // アルファベットの文字数\n    let sumPowers = 0; // L-1 文字以下の単位の総数\n    let currentPower = 1; // 基数\n \n    while (true) {\n        const unitsInThisLength = currentPower * 26;\n        if (n &lt;= sumPowers + unitsInThisLength) {\n            L++;\n            break;\n        }\n        L++;\n        sumPowers += unitsInThisLength;\n        currentPower *= 26;\n \n        // アルファベット10文字数を超えるとエラーにする（現状確認されているのは2までだが）\n        if (L &gt; 10) throw new Error(&quot;L is too large&quot;); \n    }\n \n    const nPrime = n - sumPowers - 1; // 長さL内での0基準インデックス\n \n    let notation = &quot;&quot;;\n    let tempNPrime = nPrime;\n    for (let i = 0; i &lt; L; i++) {\n        const power = 26**(L - 1 - i);\n        const index = Math.floor(tempNPrime / power);\n        if (index &lt; 0 || index &gt;= 26) throw new Error(&quot;index is out of range&quot;);\n        notation += alphabet[index];\n        tempNPrime %= power;\n    }\n    return notation;\n  }\n \n  /**\n   * ゲーム内表記文字列を返す\n   * @method toDisplayNumber\n   * @returns {string} ゲーム内表記文字列\n   */\n  toDisplayNumber() {\n    if (this.exponent &lt; 3) {\n      const value = this.mantissa * (10**this.exponent);\n      const fixedValue = value.toFixed(2);\n      const displayValue = fixedValue.endsWith(&#039;.00&#039;) ? fixedValue.slice(0, -3) : fixedValue;\n      return displayValue;\n    }\n \n    const notationIndex = Math.floor(this.exponent / 3);\n    const remainderExponent = this.exponent % 3;\n    const displayMantissa = this.mantissa * (10**remainderExponent);\n    const notationString = ChiipokeNumber.getNotationString(notationIndex);\n \n    return `${displayMantissa.toFixed(2)}${notationString}`;\n  }\n}\n使用例\n// 足し算\nconst a = new ChiipokeNumber(5.2, 20); \nconst b = new ChiipokeNumber(1.5, 21);\n \na.toDisplayNumber() \n// -&gt; &#039;520.00f&#039;\nb.toDisplayNumber() \n// -&gt; &#039;1.50g&#039;\na.add(b).toDisplayNumber() \n// -&gt; &#039;2.02g&#039;\n \n// 掛け算\nconst a = new ChiipokeNumber(5, 35); \nconst _15 = new ChiipokeNumber(15, 0);\n \na.toDisplayNumber() \n// -&gt; &#039;500.00k&#039;\na.multiply(_15).toDisplayNumber() \n// -&gt; &#039;7.50l&#039;\n \n// 超巨大な値同士の掛け算\nconst a = new ChiipokeNumber(123.456, 1234); \nconst b = new ChiipokeNumber(456.789, 5678);\n \na.toDisplayNumber()\n// -&gt; &#039;1.23ov&#039;\nb.toDisplayNumber()\n// -&gt; &#039;45.68btu&#039;\na.multiply(b).toDisplayNumber()\n// -&gt; &#039;56.39cjq&#039;\n実際のロジックはわかりませんが、このようにしてゲーム上のパラメータというユースケースにおいては非常に巨大な値を扱うことができそうです。\nおわりに\nちいぽけのゲーム、賛否両論かなりあるけど個人的にはちいかわのゲームっぽくて好きです。みんなでプレイしよう！"},"misc/obsidian-for-llm":{"slug":"misc/obsidian-for-llm","filePath":"misc/obsidian-for-llm.md","title":"LLMとなかよくするためにObsidianを使う","links":["dev/Obsidian-vaultの一部のディレクトリだけをQuartzで公開する"],"tags":["Obsidian","LLM"],"content":"Obsidianは、ローカルのMarkdownファイルを知識ベースとして活用できるノートアプリです。OSSではないですが、コミュニティによるプラグインの開発が活発で色々とカスタマイズできます。\n「ローカルにすべてある」、「拡張可能性が高い」というところがLLMと組み合わせてテキストであれこれするのにとても相性がいいと思い使い始めました。\nまだ使い始めて日が浅いんですが、今のところうまいことワークしており、NotebookLMとかはもはや使わなくなってしまいました。Obsidian x LLM周りのやってることを紹介したいと思います。\n考え方\nObsidianは普通デイリーノートを取ったり日々のアイデアを書き留めてノート同士をリンクし、非線形な知識の構造化みたいなことを目指すのだと思いますが、私は自分だけが参照するために文章を書く習慣があまりないです。\nObsidianにはとにかく情報をぶち込みまくって、LLMの補助を受けながら解釈してアウトプットすることを目的に利用しています。\nなのでグラフビューとか全く使ってないです。（たぶん邪道ではある、が満足してる）\n情報収集: 「後で読む」にぶち込むと同時にAI要約する\nObsidian Web ClipperというChrome拡張で開いているwebページのコンテンツをObsidianにノートとしてぶち込むことができます。\nそのまま使っても割といい感じにメインのコンテンツだけ切り出してmarkdown化してくれますが、Web Clipperには Interpreter 機能があり、これを使うとノートを作成する前にLLMによる処理を挟むことができます。\n例えばこんな感じで記事を要約し、この記事を読んで取るべきNextActionを挙げてくれます。\n\n（青っぽいcallout部分がAIが生成したテキストです）\n後で読もうと思った記事が新規タブに溜まりがちでしたが、とりあえずweb clipperで要約付きのノートを作成しておいて、後でまとめて目を通すようになりました。\n後で読むリストは、優先度と読んだフラグ付きで一覧化され、優先度の降順で表示されるようにしています。\n\nweb clipperの設定\nObsidian Web Clipperから拡張機能をインストールし、拡張機能の settings &gt; Interpreter で任意のモデルを追加してAPIキーを入力します。\nその後、 New template からテンプレートを作成し、Note contentを以下のようにします。\n&gt; [!abstract] Interpreter Note\n&gt; \n&gt; {{&quot;コンテンツを日本語で要約してください。\\n- **共通ルール**\\n  - 読者はベンチャーキャピタリストかつソフトウェア開発者\\n  - 空白行やheading含むすべての行は `&gt; ` で開始して引用であることを示す\\n  - listで句点を利用せず、補足はインデントを付ける\\n- **フォーマット**\\n&gt; ## Summary\\n最大10個のbullet list(`- `)で箇条書きにより要約する。 \\n&gt; ## NextAction\\n最大で3個のcheckbox(`- [ ] ` で出力する。&quot;}}\n\n{{content}}\n\nスニペットは改行できなかったので \\n で改行を表現している感じです。 {{content}} に実際に保存されるコンテンツがmarkdownで入るので、要約以外にも色々やれます。\nリスト化の設定\nDataviewプラグインを使います。プラグインをインストールし、 _index などリストを表示したいページに以下のようにfrontmatter yamlとdataviewで実行したいjsのコードを書きます。\n---\nsearch: \ncssclasses:\n  - table-wide\n  - table-nowrap\n  - table-tiny\n  - row-alt\n---\n\ndataviewに実行させるには、jsの部分は以下のようにcodeblockで入力する必要があります。\n```dataviewjs\nconst MAX = 64000\n \nconst q = dv.current().search || &quot;&quot;\nconst s = dv.current().file.folder\n \nconst d = dv.pages(`&quot;${s}&quot;`).file\n  .filter(x =&gt; x.name.includes(q))\n  .filter(x =&gt; x.name !== &quot;_Index&quot;)\n  .sort(x =&gt; x.mtime, &quot;desc&quot;)\n  .sort(x =&gt; {\n    const priority = x.frontmatter.priority;\n    if (priority === undefined || priority === null) return 1;\n    const numPriority = Number(priority);\n    return isNaN(numPriority) ? 1 : -numPriority;\n  })\n  .sort(x =&gt; x.frontmatter.read ? 1 : 0)\n  .limit(100)\n  .map(x =&gt; {\n  return [\n    x.frontmatter.read ? &#039;✅&#039; : &#039;&#039;, \n    x.frontmatter.priority,\n    x.link, \n    `&lt;progress value=${x.size/MAX}&gt;&lt;/progress&gt;`,\n    x.mday.toLocaleString()\n  ]})\n  dv.table([&quot;read&quot;, &quot;priority&quot;, &quot;&quot;, &quot;size&quot;, &quot;updated&quot;], d)\n`\\`` &lt;- バッククオートはエスケープです。消してください！\nこの例では日付で降順にしたあとpriorityでまた降順にし、readが true になっているものを最後に持っていっています。jsなので好きに実装可能です。\n情報へのアクセス: CursorとObsidian Copilot\nObsidianのvaultはCursorなどのエディタで開けば単なるmarkdownファイルなので、Q&amp;Aやプランニングなど、様々なことに活用できます。\n例えば筋トレの計画を立てるときは、YouTubeでもブログでもなんでもいいのでweb clipperで参照できる情報をどんどん突っ込んで、LLMといっしょに目標達成の道筋を考えることができます。\n.cursor/rules にディレクトリ構造など明示して育てていくのが良いと思います。\n一応 Obsidian Copilot というプラグインもあり、vaultをindex化してchatしたり、事前に設定した機能（選択範囲の翻訳など）にインスタントにアクセスすることもできます。こんな感じに。\n\nまあCursorで代替できるのであまり使ってないです。\n設定手順は Obsidian Copilotのすゝめ：ノート活動を変えるかもしれない壁打ち相手 - Qiita で詳しく解説されています。\nアウトプット: CursorとObsidianでブログを書く\nこのブログはObsidianで書いています。詳しい構築方法は Obsidian vaultの一部のディレクトリだけをQuartzで公開する で紹介しています。\n上記までのプライベートな用途のvaultと同じvault内でブログ記事も管理しており、そうすることでLLMで相互に参照しやすくしています。\n現状は、Cursorで記事の一部を書いてもらったり、記事のレビューをしてもらったりしているくらいですが、将来的には人間はレビューして承認するだけみたいな運用にしても良さそうです。（もちろん、ネットの海にゴミを増やすようなマネはしないようにケアしつつ）\nまとめ\nという感じに、情報のインプットからアウトプットまでをObsidianをハブにして運用しつつ、ほんのりLLMのサポートを受けているという感じです。\nNotion MCPが公式から公開されましたが、このユースケースは代替できないと思います。（APIをガンガン叩かないといけなかったりなど）\nなので移行とかはせずにどっちも使っていきます。"},"news/ai_news_veo2_kling2":{"slug":"news/ai_news_veo2_kling2","filePath":"news/ai_news_veo2_kling2.md","title":"【bot投稿🤖】最新AIニュース Veo 2とKling 2が一般公開 GPT-4.1も","links":[],"tags":["自動生成記事","LMM"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nこの記事は、以下の情報源を参照し、LLMにより自動で生成・投稿された記事です。\n\nAI News ButtonDown\n\n内容の正確性にご注意ください。\n\n\n最新AIニュースまとめ Veo 2とKling 2が一般公開\nAIの世界は相変わらず動きが早いですね。今回は特に動画生成モデルの分野で大きな進展がありました。Googleの「Veo 2」と中国発の「Kling 2」という、現在トップクラスとされる動画生成モデルが開発者向けに一般公開されました。\nその他にも、OpenAIが新しい「GPT-4.1」ファミリーを発表したり、各種開発ツールやコミュニティで活発な動きが見られたり、AI研究の最前線からの興味深い報告があったりと、盛りだくさんです。さっそく詳しく見ていきましょう。\n動画生成モデルの進化が止まらない Veo 2 と Kling 2\nこれまでAI Newsではテキストやコーディング関連の話題が中心でしたが、今回は動画生成モデルの大きなニュースを取り上げます。\nArtificial Analysisの動画生成モデルリーダーボードでトップを争う2つのモデルが、ほぼ同時に開発者向けにAPIアクセスを開放しました。これは動画生成技術の現状を知る良い機会ですね。\nGoogle Veo 2\nGoogleの「Veo 2」は、Gemini API と Gemini Advanced/Whisk を通じて利用可能になりました。（以前はFal.ai経由での提供でした）\n注目すべきはその価格で、生成される動画1秒あたり35セントと、かなり手頃になっています。（ただし、実際の利用感とは異なる可能性もあるようです）\n生成される動画の品質も向上しており、物理法則への暗黙的な理解が素晴らしいとの声も上がっています。\n\nKuaishou Kling 2\n中国の快手（Kuaishou）が開発した「Kling 2」も同日に発表されました。\n価格は10秒のクリップで約2ドルとVeo 2より高価ですが、生成される動画の品質は非常に高いと評判です。ただし、利用には最低でも月額700ドル（3ヶ月契約）のパッケージ購入が必要となるようです。\n\nどちらのモデルも、テキストから高品質な動画を生成できる能力を示しており、今後のクリエイティブ分野での活用が期待されます。\nOpenAIから「GPT-4.1」ファミリーが登場\nOpenAIも負けじと新しいモデルファミリー「GPT-4.1」を発表しました。(OpenAIのアナウンス)\nAPI限定リリースとモデルラインナップ\n今回のリリースはAPI限定で、以下の3つのモデルが含まれます。\n\nGPT-4.1\nGPT-4.1 mini\nGPT-4.1 nano\n\nOpenAI Devsのポストによると、これらのモデルはAPI専用であり、既存のGPT-4.5 Previewは3ヶ月後の7月14日に廃止される予定です。GPT-4.1が同等以上の性能を低遅延・低コストで提供できるためとのこと。\n性能向上と特徴\nOpenAIの発表や開発者の声によると、以下の点が改善されています。\n\nコーディング能力の向上\n\nGPT-4.1はSWE-Bench Verifiedで54-55%という高いスコアを達成（Reasoningモデルではないにも関わらず）\n内部ベンチマークではGPT-4o比で60%改善（不要なファイル読み取り40%減、変更70%減、冗長性50%減）という報告も\n\n\n指示追従性の改善\n長文コンテキスト処理能力の向上\n\n最大100万トークンに対応\n\n\nコスト削減\n\nGPT-4oと比較して26%安価\n\n\n\n評価とベンチマーク\n一方で、Scaling01氏のように、API版のGPT-4.1はOpenRouterのプレビュー版（Quasar Alpha, Optimus Alpha）よりも性能が低い、mini版は他の多くのモデルよりスコアが低い、といった指摘もあります。また、コーディング性能では依然としてDeepSeekV3に劣るものの、価格は8倍という比較も。\nしかし、skirano氏は、GPT-4.1がベンチマークスコアだけでなく、**現実世界のタスク（特にフロントエンド開発やWebサイト構築）**に最適化されている可能性があると指摘しています。OpenAIのSam Altman氏も、ベンチマークは強力だが、現実世界での実用性に焦点を当てたと述べています。\nまた、Aidan Clark氏は「名付けは下手だけど、miniと付くモデルは🔥だよ」とコメントしており、miniモデルの性能にも期待が持てそうです。DiscordのLMArenaコミュニティでも、GPT-4.1 miniがGPQAベンチマークでフルバージョンに匹敵する結果を出したという観察が共有されています。\n移行を支援するためのプロンプティングガイドも公開されています。\nその他注目モデルとツール動向\n動画生成やGPT-4.1以外にも、多くのモデルやツールが登場・アップデートされています。\n\nマルチモーダルモデル\n\nByteDanceがスケーラブルで統合的なマルチモーダル生成のための言語モデル「Liquid」をHugging Faceで公開\n\n\n音声・音響モデル\n\nGoogle DeepMindがイルカのコミュニケーション解析を支援するAIモデル「DolphinGemma」を発表\n\n\n言語モデル\n\nZhipu AIが「GLM-4」をリリース。DeepSeek DistillやQwen 2.5 Maxに匹敵する性能でMITライセンス\n\n\n推論エンジン\n\nDeepSeekが推論エンジンをオープンソース化 (LMSys SGLang, vLLM Projectとの協力)\n\n\n開発フレームワーク・ツール\n\nAider: Grok-3やOptimusモデル、GPT-4.1をサポート追加\nLlamaIndex: GPT-4.1をサポート、SkySQLとの連携強化、階層型マルチエージェントシステムのデモ\nAnyAgent: LlamaIndex向けのエージェント管理ライブラリが登場 (GitHub)\nVidTrainPrep: 動画から学習データセットを準備するツール (GitHub)\n\n\nハードウェア関連\n\nCUDA: CUDA 12ランタイムがRTX 3090で遅いという報告\nRTX 5090: 高価格とVRAM制限でホビイストには厳しいか\nROCm: RunpodでROCm 6.2/6.3へのアップグレード成功\nMetal: 新しいcandle-metal-kernelsでApple Siliconのパフォーマンス向上\n\n\nIDE連携とAPIアクセス\n\nコーディングIDE「RooCode」が高評価。ただしGitHub Copilot連携には課題も\nGitHub CopilotのAPIキーを不正利用するとBANのリスク\nMicrosoftがライセンス問題でVSCode拡張機能の利用を制限する動き\n\n\n\nコミュニティとオープンソースの動向\n開発者コミュニティやオープンソースプロジェクトも活発です。\n/r/LocalLlama の声\nRedditの/r/LocalLlamaコミュニティでは、以下のような議論が注目を集めています。\n\nllama.cppへの敬意: MetaのLlama 4発表ブログで、ローカルLLM実行の基盤となっているllama.cppとその開発者ggerganov氏への言及がないことに対し、不公平だという声が上がっています。ラッパーであるOllamaばかりが注目される状況に疑問が呈されています。\nOpenAIへの失望: OpenAIが期待されていたオープンソースモデルをリリースしなかったことに対する失望の声が見られます。\n\nDiscordコミュニティの活発な動き\n各種Discordサーバーでも、ツール開発や情報共有が盛んに行われています。\n\n便利なツールの公開\n\nGrokのようにWebページを要約できるChrome拡張機能 (GitHub)\nProject EchoCoreがオープンソース化 (GitHub)\n\n\n共同プロジェクトの呼びかけ\n\nOpen Empathicプロジェクトがカテゴリ拡張のための協力者を募集 (YouTubeチュートリアル, GitHub)\nFast MCPを利用したGoogle Docs MCP開発の協力者募集 (デモ動画)\n\n\nモデル間の連携\n\n新しいShisa-v2モデルの一部で、UnslothのLlamafied Phi4を採用し、Liger互換性などを実現 (Hugging Face)\n\n\nバグや制限に関する情報共有\n\nGPT-4oの80メッセージ制限に達すると性能が低下する問題\nGPT-4.1が従来と異なるMarkdown構造を返す問題\nGemini 2.5 ProがLaTeXフォーマットに失敗する、「思考中」でスタックする問題\nRunPodのJupyter Notebookセッションが予期せず終了する問題\nPerplexity AIのクレジットカード支払い問題\nHugging Faceの一時的な500エラー\n\n\n\n最先端の研究動向\nAI研究の分野でも興味深い発表が続いています。\n\nGoogle DeepMind\n\n強化学習(RL)を用いて、自己改善するRLアルゴリズムをAIが自ら構築し、人間が開発したアルゴリズムを凌駕 (David Silver氏の講演動画)\nAGI（汎用人工知能）後の時代に向けた準備を進めている可能性\n\n\nMIT\n\n観測データのみから、AI（LNN）が事前知識なしにハミルトニアン物理学に相当する理論を自律的に発見 (論文PDF)\n\n\nEleutherAI @ ICLR\n\n国際会議ICLRで高い採択率（5/9）を達成\n発表論文例:\n\n言語モデルにおける記憶現象 (論文)\nテキスト・音声・動画にわたるデータ起源の追跡 (論文)\n言語モデル事前学習における安定性と外れ値 (論文)\n記号音楽モデリングのためのMIDIデータセット「Aria-MIDI」 (論文PDF)\n\n\n\n\nその他の研究\n\nDeep CogitoがIDA（Iterated Distillation and Amplification）という手法を用いた「Cogito V1」モデルのプレビュー版を公開\nCephプロジェクトがllama.cppにKey/Valueストレージを追加し、ランタイムでの記号的推論フレームワーク構築を目指す\nAppleが差分プライバシーを用いた分散強化学習によるAIモデル改善のアプローチを発表。プライバシーに関する議論も\n\n\n\nまとめ\n今回は、特に動画生成モデルの一般公開とGPT-4.1ファミリーの登場という大きなニュースがありました。これらのモデルが開発者の手に渡ることで、どのような新しいアプリケーションやサービスが生まれるのか、非常に楽しみです。\nまた、小規模モデルの性能向上、開発ツールの進化、活発なコミュニティ活動、そしてAI自身が新たな発見をするような最先端の研究まで、AI分野全体のダイナミックな動きが感じられるニュースが満載でした。\n今後もこれらの技術動向やコミュニティの動きに注目していきたいと思います。"},"news/openai-gpt41-launch":{"slug":"news/openai-gpt41-launch","filePath":"news/openai-gpt41-launch.md","title":"【bot投稿🤖】OpenAIの新主力モデルGPT4.1 API提供開始","links":[],"tags":["自動生成記事","LMM"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nこの記事は、以下の情報源を参照し、LLMにより自動で生成・投稿された記事です。\n\nAI News ButtonDown\n\n内容の正確性にご注意ください。\n\n\nOpenAIが新しいモデルファミリー「GPT-4.1」を発表しましたね！ GPT-4.1、GPT-4.1 mini、そしてGPT-4.1 nanoの3つのモデルがAPIで利用可能になったとのことです。\n今回のアップデートでは、特にコーディング能力、指示への追従性、そして長文コンテキストの処理能力が向上したとされています。開発者にとってはかなり気になるアップデートではないでしょうか。\nOpenAIの発表はこちら\nGPT-4.1 ファミリーってどんな感じ？\n今回発表されたのは、以下の3つのモデルです。\n\nGPT-4.1: フラッグシップモデル。複雑なタスク、コーディング、長文コンテキスト（最大100万トークン！）に強い\nGPT-4.1 mini: GPT-4oに匹敵する能力を持ちつつ、より高速で安価\nGPT-4.1 nano: 最も高速かつ低コスト。0.10/1M入力、0.40/1M出力という価格設定\n\nキャッシュ利用時は入力$0.03/1M\n\n\n\n具体的な改善点\nOpenAIによると、GPT-4.1はGPT-4oと比較していくつかの点で改善が見られるようです。\n\nコーディング能力: 特にフロントエンド開発スキルが向上し、ツールの利用もより信頼性が高くなった\n\nSWE-Bench Verifiedで54-55%のスコアを達成したという報告も (@kevinweil, @polynoamial)\nWindsurf AIの内部ベンチマークでは、GPT-4oに対して60%改善、不要なファイルの読み取りを40%削減、不要なファイルの変更を70%削減したとのこと (@omarsar0)\n\n\n指示への追従性: 指定されたフォーマットの遵守、否定的な指示（〜しないで）の理解、指示された順序の維持などがより正確になった (@OpenAIDevs)\n長文コンテキスト: 最大100万トークンのコンテキストウィンドウを処理可能\n\nOpenAIは新しいプロンプティングガイドとCookbookも公開しています。\n\nプロンプティングガイド\nCookbook\n\nまた、この発表に合わせてLatent Spaceで新しいインタビュー動画も公開されています。\n\nGPT-4.5 Previewは廃止へ\n今回のGPT-4.1リリースに伴い、APIで提供されていたGPT-4.5 Previewは廃止されることになりました。OpenAIによると、GPT-4.1が同等以上の性能を提供するためとのことです。2025年7月14日には完全に利用できなくなります (@OpenAIDevs)。\n開発ツールやサービスの対応状況\n新しいモデルが登場すると、関連するツールやサービスの対応が気になりますよね。今回も素早い動きが見られました。\n\nCursor: GPT-4.1を即座に追加し、当面は無料で提供すると発表 (Xのポスト)。Cursor Communityでは、GPT-4.1が新しい標準になり、Gemini 2.5 ProのUIデザイン能力も高く評価されているようです。\nWindsurf AI: GPT-4.1をデフォルトモデルにし、1週間限定で無料無制限利用を提供。その後も割引価格で提供予定とのこと (@windsurf_ai)。\nOpenRouter: GPT-4.1、Mini、Nanoを迅速に追加。以前テスト提供していたOptimus AlphaとQuasar AlphaがGPT-4.1の初期バージョンだったことも明らかに (OpenRouter Announcements)。\nLlamaIndex: Day 0でGPT-4.1 APIをサポート開始 (llama-index-llms-openai経由) (@llama_index)。\nAider: バージョン0.82.0でGPT-4.1をサポート。OpenAIの新しいpatch編集フォーマットにも対応したようです (Aider History)。\n\n各ツールでの使い勝手やパフォーマンスがどう変わるか、試してみるのが楽しみですね。\n競合モデルも活発\nOpenAIの動きに合わせて、他のAI企業やプロジェクトも活発に動いています。\n\nGoogle Gemini: Gemini 2.5 Proは高い評価を得ており、特にデバッグ、リファクタリング、大規模コードベースの理解に優れているとの声があります (@omarsar0)。UIデザイン能力も「insane」と評されています。一方で、ツール呼び出し機能がnerfされた（弱体化された）という報告や、長文プロンプトの割引終了など、変化も見られます。Gemini 2.0 Flashも低価格で登場しています。\nMeta Llama 4: ネイティブマルチモーダル対応、最大1000万トークンのコンテキストウィンドウを持つLlama 4ファミリー（Scout, Maverick, Behemoth）がオープンソースでリリースされました (@adcock_brett)。MaverickはGPT-4oのベンチマークを超えるとも言われています。\nDeepSeek: 推論エンジンの一部をオープンソースコミュニティに貢献することを発表 (GitHub)。また、効率的な14Bパラメータで高性能なコーディング能力を持つDeepCoderも注目されています。\nNvidia: LlamaベースのNemotron-Ultra (253B)をリリース。DeepSeek R1やLlama 4 Behemoth/Maverickを上回る性能を持つオープンソースモデルとされています (@adcock_brett)。\nその他: Mistralの長文モデル、GLM-4の新モデル（特に9Bモデル）、プログラミング言語Lean向けのKimina-Proverなども登場しています。\n\nモデル間の競争はますます激しくなっていますね。\nその他の注目トピック\n今回の発表周辺では、他にもいくつか興味深い動きがありました。\n\nOpenAIの科学的発見支援モデル: OpenAIが「o3」や「o4-mini」と呼ばれる新しい推論モデルを準備中で、これらが科学的なアイデアを自律的に生み出す能力を持つ可能性があるという噂があります (The Information)。\nロボティクス: Hugging FaceがオープンソースロボットメーカーのPollen Roboticsを買収 (@ben_burtenshaw)。SamsungがGoogle Geminiを搭載した家庭用ロボット「Ballie」を発表 (@adcock_brett)。\nAI研究: 事前学習中に「Reflection（自己反省）」能力が現れるという研究や、強化学習が推論モデルの応答を長くする傾向についての研究などが発表されています。\n\nAIの進化は本当に止まらないですね。\nまとめ\nGPT-4.1ファミリーの登場は、開発者にとって選択肢が増え、より高性能なモデルをより安価に利用できる可能性を示唆しています。特にコーディング能力の向上は多くの開発現場で歓迎されるでしょう。\nAPIでの提供が中心となるため、ChatGPTでの直接的な体験は限定的かもしれませんが、CursorやWindsurf AIなどのツールを通じて、その実力を試すことができます。\n一方で、GeminiやLlama、DeepSeekなども進化を続けており、どのモデルが特定のタスクに最適なのか、引き続き注目していく必要がありそうです。今後のAIエコシステムの発展がますます楽しみですね！"}}